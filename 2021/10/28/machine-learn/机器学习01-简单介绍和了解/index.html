



<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#FFF">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">

<link rel="icon" type="image/ico" sizes="32x32" href="/images/favicon.ico">
  <meta http-equiv="Cache-Control" content="no-transform">
  <meta http-equiv="Cache-Control" content="no-siteapp">


<link rel="alternate" type="application/rss+xml" title="方家小白" href="https://fangjiaxiaobai.github.io/rss.xml" />
<link rel="alternate" type="application/atom+xml" title="方家小白" href="https://fangjiaxiaobai.github.io/atom.xml" />
<link rel="alternate" type="application/json" title="方家小白" href="https://fangjiaxiaobai.github.io/feed.json" />

<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Mulish:300,300italic,400,400italic,700,700italic%7CFredericka%20the%20Great:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20JP:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20SC:300,300italic,400,400italic,700,700italic%7CInconsolata:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="/css/app.css?v=0.2.5">

  
  <meta name="keywords" content="MachineLearn" />


<link rel="canonical" href="https://fangjiaxiaobai.github.io/2021/10/28/machine-learn/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A001-%E7%AE%80%E5%8D%95%E4%BB%8B%E7%BB%8D%E5%92%8C%E4%BA%86%E8%A7%A3/">



  <title>
机器学习 - 简介 - MachineLearn |
方家小白 = 和你一起遇见更好的自己</title>
<meta name="generator" content="Hexo 5.4.0"></head>
<body itemscope itemtype="http://schema.org/WebPage">
  <div id="loading">
    <div class="cat">
      <div class="body"></div>
      <div class="head">
        <div class="face"></div>
      </div>
      <div class="foot">
        <div class="tummy-end"></div>
        <div class="bottom"></div>
        <div class="legs left"></div>
        <div class="legs right"></div>
      </div>
      <div class="paw">
        <div class="hands left"></div>
        <div class="hands right"></div>
      </div>
    </div>
  </div>
  <div id="container">
    <header id="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="inner">
        <div id="brand">
          <div class="pjax">
          
  <h1 itemprop="name headline">机器学习 - 简介
  </h1>
  
<div class="meta">
  <span class="item" title="创建时间：2021-10-28 18:18:00">
    <span class="icon">
      <i class="ic i-calendar"></i>
    </span>
    <span class="text">发表于</span>
    <time itemprop="dateCreated datePublished" datetime="2021-10-28T18:18:00+08:00">2021-10-28</time>
  </span>
  <span class="item" title="本文字数">
    <span class="icon">
      <i class="ic i-pen"></i>
    </span>
    <span class="text">本文字数</span>
    <span>5k</span>
    <span class="text">字</span>
  </span>
  <span class="item" title="阅读时长">
    <span class="icon">
      <i class="ic i-clock"></i>
    </span>
    <span class="text">阅读时长</span>
    <span>5 分钟</span>
  </span>
</div>


          </div>
        </div>
        <nav id="nav">
  <div class="inner">
    <div class="toggle">
      <div class="lines" aria-label="切换导航栏">
        <span class="line"></span>
        <span class="line"></span>
        <span class="line"></span>
      </div>
    </div>
    <ul class="menu">
      <li class="item title"><a href="/" rel="start">方家小白</a></li>
    </ul>
    <ul class="right">
      <li class="item theme">
        <i class="ic i-sun"></i>
      </li>
      <li class="item search">
        <i class="ic i-search"></i>
      </li>
    </ul>
  </div>
</nav>

      </div>
      <div id="imgs" class="pjax">
        <ul>
          <li class="item" data-background-image="https://tva2.sinaimg.cn/large/6833939bly1gipesrnqv3j20zk0m8ava.jpg"></li>
          <li class="item" data-background-image="https://tva2.sinaimg.cn/large/6833939bly1giciukx8a7j20zk0m8aio.jpg"></li>
          <li class="item" data-background-image="https://tva2.sinaimg.cn/large/6833939bly1giclj9410cj20zk0m8h12.jpg"></li>
          <li class="item" data-background-image="https://tva2.sinaimg.cn/large/6833939bly1gipetv6p75j20zk0m8x6p.jpg"></li>
          <li class="item" data-background-image="https://tva2.sinaimg.cn/large/6833939bly1giclgi503lj20zk0m8hdt.jpg"></li>
          <li class="item" data-background-image="https://tva2.sinaimg.cn/large/6833939bly1giclwrdwyaj20zk0m8are.jpg"></li>
        </ul>
      </div>
    </header>
    <div id="waves">
      <svg class="waves" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto">
        <defs>
          <path id="gentle-wave" d="M-160 44c30 0 58-18 88-18s 58 18 88 18 58-18 88-18 58 18 88 18 v44h-352z" />
        </defs>
        <g class="parallax">
          <use xlink:href="#gentle-wave" x="48" y="0" />
          <use xlink:href="#gentle-wave" x="48" y="3" />
          <use xlink:href="#gentle-wave" x="48" y="5" />
          <use xlink:href="#gentle-wave" x="48" y="7" />
        </g>
      </svg>
    </div>
    <main>
      <div class="inner">
        <div id="main" class="pjax">
          
  <div class="article wrap">
    
<div class="breadcrumb" itemscope itemtype="https://schema.org/BreadcrumbList">
<i class="ic i-home"></i>
<span><a href="/">首页</a></span><i class="ic i-angle-right"></i>
<span  class="current" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/MachineLearn/" itemprop="item" rel="index" title="分类于 MachineLearn"><span itemprop="name">MachineLearn</span></a>
<meta itemprop="position" content="1" /></span>
</div>

    <article itemscope itemtype="http://schema.org/Article" class="post block" lang="zh-CN">
  <link itemprop="mainEntityOfPage" href="https://fangjiaxiaobai.github.io/2021/10/28/machine-learn/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A001-%E7%AE%80%E5%8D%95%E4%BB%8B%E7%BB%8D%E5%92%8C%E4%BA%86%E8%A7%A3/">

  <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="image" content="/images/avatar.jpg">
    <meta itemprop="name" content="方小白">
    <meta itemprop="description" content="和你一起遇见更好的自己, 和你一起遇见更好的自己">
  </span>

  <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="方家小白">
  </span>

  <div class="body md" itemprop="articleBody">
    

    <h2 id="概述"><a class="markdownIt-Anchor" href="#概述">#</a> 概述</h2>
<h3 id="什么是机器学习"><a class="markdownIt-Anchor" href="#什么是机器学习">#</a> 什么是机器学习</h3>
<p>从历史数据中自动分析获得规律 (模型), 并利用规律对未知数据进行预测。</p>
<h3 id="为什么需要机器学习"><a class="markdownIt-Anchor" href="#为什么需要机器学习">#</a> 为什么需要机器学习</h3>
<p>解放生产力：智能客服<br>
解决专业问题: ET 医疗<br>
提供社会便利：提供社会便利</p>
<h3 id="机器学习的应用场景"><a class="markdownIt-Anchor" href="#机器学习的应用场景">#</a> 机器学习的应用场景</h3>
<p>方方面面</p>
<h2 id="机器学习的工作流程"><a class="markdownIt-Anchor" href="#机器学习的工作流程">#</a> 机器学习的工作流程</h2>
<p>获取数据 -&gt; 数据基本处理 -&gt; 特征工程 -&gt; 机器学习 (模型训练) -&gt; 模型评估。</p>
<p>评估符合要求，则上线服务。如果不符合要求，则重复上述步骤。</p>
<h2 id="数据集的结构"><a class="markdownIt-Anchor" href="#数据集的结构">#</a> 数据集的结构</h2>
<p>机器学习的数据大部分数据存储到文件中。数据库中间件 (mysql,nosql) 等性能瓶颈，读取速度，格式不符合机器学习要求的数据格式。<br>
numpy 非常快，因为什么？释放了 GIL。</p>
<p>在数据集中：<br>
一行数据成为一个样本。<br>
一列数据称为一个特征。</p>
<h3 id="可用的数据集"><a class="markdownIt-Anchor" href="#可用的数据集">#</a> 可用的数据集</h3>
<p>Kaggle: 大数据竞赛平台，80 万科学家，真实数据，数据量巨大 <span class="exturl" data-url="aHR0cHM6Ly93d3cua2FnZ2xlLmNvbS9kYXRhc2V0cw==">https://www.kaggle.com/datasets</span></p>
<p>UCI: 收录了 360 个数据集。覆盖科学，生活经济等领域，数据量几十万 <span class="exturl" data-url="aHR0cDovL2FyY2hpdmUuaWNzLnVjaS5lZHUvbWwvaW5kZXgucGhw">http://archive.ics.uci.edu/ml/index.php</span></p>
<p>scikit-learn: 数据量小，方便学习。<span class="exturl" data-url="aHR0cHM6Ly9zY2lraXQtbGVhcm4ub3JnL3N0YWJsZS8saHR0cHM6Ly9zY2lraXQtbGVhcm4ub3JnL3N0YWJsZS9zdGFibGUvZGF0YXNldHMvaW5kZXguaHRtbA==">https://scikit-learn.org/stable/,https://scikit-learn.org/stable/stable/datasets/index.html</span></p>
<h3 id="常用数据集数据的结构组成"><a class="markdownIt-Anchor" href="#常用数据集数据的结构组成">#</a> 常用数据集数据的结构组成</h3>
<ul>
<li>特征值 + 目标值 (目标值是练习的和离散的)。特征？比如分辨男女，一个人身高体重皮肤颜色，头发长度。都是特征值。目标值：这个人是男是女，就是目标值。</li>
<li>只有特征值，没有目标值</li>
</ul>
<h3 id="数据分割"><a class="markdownIt-Anchor" href="#数据分割">#</a> 数据分割</h3>
<p>机器学习一般的数据集会划分为两个部分。</p>
<ul>
<li>训练数据：用于训练，构建模型</li>
<li>测试数据：在数据检验时使用，用于评估模型是否有效、</li>
</ul>
<p>划分比例：</p>
<ul>
<li>训练集： 79% 80% 75%</li>
<li>测试集： 30%， 20% 25%</li>
</ul>
<h2 id="数据的特征工程"><a class="markdownIt-Anchor" href="#数据的特征工程">#</a> 数据的特征工程</h2>
<h3 id="数据特征是什么"><a class="markdownIt-Anchor" href="#数据特征是什么">#</a> 数据特征是什么</h3>
<p>将原始数据转换为更好的代表预测模型的潜在问题的特征的过程，从而提高对未知数据的预测准确性。</p>
<p>使用专业背景知识和技巧处理数据，使得特征能在机器学习算法上发送更好的作用的过程。</p>
<ul>
<li>
<p>特征提取： 将任意数据 (文本或者图像) 转换为可用于机器学习的数字特征。</p>
</li>
<li>
<p>特征预处理：通过转化函数将特征数据转换成更加适合算法模型的特征数据过程。</p>
<ul>
<li>归一化：为什么要进行归一化？特征的单位或者大小相差较大，或者某特征的方法相比其他特征要大出几个数量级，容易影响 (支配) 目标结果，使得算法无法学习到其他的特征。
<ul>
<li>归一化的定义： 通过对原始数据进行变换，把数据映射到默认 <code>[0,1]</code>  之间。<br>
计算公式:<br>
<img data-src="./images/%E5%BD%92%E4%B8%80%E5%8C%96%E5%85%AC%E5%BC%8F.png" alt=""></li>
</ul>
</li>
<li>标准化：通过对原始数据进行把数据变换到均值为 0，标准差为 1 的范围内。<br>
<img data-src="./images/%E6%A0%87%E5%87%86%E5%8C%96%E5%85%AC%E5%BC%8F.png" alt=""><br>
对于归一化来说：如果出现异常点，影响了最大值和最小值，那么结果显然会发生改变<br>
对于标准化来说：如果出现异常点，由于具有一定数据量，少量的异常点对于平均值的影响并不大，从而方差改变较小。</li>
</ul>
</li>
<li>
<p>特征降维：指在限定条件下，降低随机变量 (特征) 个数，得到一组 &quot;不相关&quot; 主变量的过程。<br>
减少特征的数量，同时保留原来数据的大部分信息。可以通过 PCA 算法来是实现特征降维。</p>
</li>
</ul>
<p>为什么要降维呢？随着数据维度不断降低，数据存储所需的空间也会随之减少。低维数据有助于减少计算 / 训练用时。一些算法在高维度数据上容易表现不佳，降维可提高算法可用性。降维可以用删除冗余特征解决多重共线性问题。比如我们有两个变量：“一段时间内在跑步机上的耗时” 和 “卡路里消耗量”。这两个变量高度相关，在跑步机上花的时间越长，燃烧的卡路里自然就越多。因此，同时存储这两个数据意义不大，只需一个就够了。降维有助于数据可视化。如前所述，如果数据维度很高，可视化会变得相当困难，而绘制二维三维数据的图表非常简单。</p>
<h3 id="特征工程的意义"><a class="markdownIt-Anchor" href="#特征工程的意义">#</a> 特征工程的意义</h3>
<p>直接影响预测结果。</p>
<h4 id="特征抽取实例演示"><a class="markdownIt-Anchor" href="#特征抽取实例演示">#</a> 特征抽取实例演示</h4>
<h4 id="特征抽取api"><a class="markdownIt-Anchor" href="#特征抽取api">#</a> 特征抽取 API</h4>
<p>字典特征抽取类:   <code>sklearn.feature_extraction.DictVectorizer</code> <br>
 作用：对字典进行特征值化。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">DictVectorizer(sparse=<span class="literal">True</span>,....)</span><br><span class="line"></span><br><span class="line"><span class="comment"># X: 字典或者包含字典的迭代器</span></span><br><span class="line"><span class="comment"># 返回值: 返回sparse矩阵</span></span><br><span class="line">DictVectorizer.fit_transform(X):</span><br><span class="line"></span><br><span class="line"><span class="comment"># X: array数组或者sparse矩阵</span></span><br><span class="line"><span class="comment"># 返回值: 转换之前的数据格式</span></span><br><span class="line">DictVectorizer.invers_transform(X)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 返回类别名称</span></span><br><span class="line">DictVectorizer.get_feature_names()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 按照原先的标准转换</span></span><br><span class="line">DictVectorizerr.transform(X)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h5 id="使用流程"><a class="markdownIt-Anchor" href="#使用流程">#</a> 使用流程</h5>
<p>1. 实例化类 DictVectorizer<br>
2. 调用 fit_transform 方法进行特征抽取</p>
<h4 id="字典数据提取的现象"><a class="markdownIt-Anchor" href="#字典数据提取的现象">#</a> 字典数据提取的现象:</h4>
<p>把字典中国的一些类别数据，分别进行转换特征数据。</p>
<blockquote>
<p>文本特征抽取 Count</p>
</blockquote>
<h4 id="作用-对文本数据进行特征值化"><a class="markdownIt-Anchor" href="#作用-对文本数据进行特征值化">#</a> 作用：对文本数据进行特征值化</h4>
<h4 id="类-sklearnfeature_extractiontextcountvectorizer"><a class="markdownIt-Anchor" href="#类-sklearnfeature_extractiontextcountvectorizer">#</a> 类: sklearn.feature_extraction.text.CountVectorizer</h4>
<h4 id="api"><a class="markdownIt-Anchor" href="#api">#</a> API</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 返回的是词频矩阵</span></span><br><span class="line">CountVectorizer()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 统计所有文章中出现的词的位置标识，对应着列表中的单词(单个字母不统计,不支持中文,需要使用jieba分词)，</span></span><br><span class="line">    <span class="comment"># X 文本或者包含文本字符串的可迭代对象</span></span><br><span class="line">    <span class="comment"># 返回值: 返回sparse矩阵</span></span><br><span class="line">    CountVectorizer.fit_transform(X)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># X： array数据或者sparse矩阵</span></span><br><span class="line">    <span class="comment"># 返回值：转换之前的数据格式</span></span><br><span class="line">    CountVetorizer.inverse_transform(X)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 返回值: 单词列表</span></span><br><span class="line">    CountVetorizer.get_feature_names()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<blockquote>
<p>文本特征抽取 tfidf</p>
</blockquote>
<p>主要思想是： 如果某个词或短语在一篇文章中出现的概率高，b 并且在其他文章中很少出现，则认为该词或者短语具有很好的类别区分能力，适合用来分类。</p>
<p>TF-IDF 的作用：  用以评估一字词对于一个文件集成一个语料库中的其中一份文件的重要程度。</p>
<p>tf (term frequency 词的频率)<br>
 idf (inverse document frequency 逆文档频率) log (总文档数据 / 该词出现的文档数量)</p>
<p>tf * idf 这个值称为重要性。</p>
<h4 id="类-sklearnfeature_extractiontexttfidfvectorizer"><a class="markdownIt-Anchor" href="#类-sklearnfeature_extractiontexttfidfvectorizer">#</a> 类  <code>sklearn.feature_extraction.text.TfidfVectorizer </code></h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 返回的是词频矩阵</span></span><br><span class="line">CountVectorizer(stop_worlds=N)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 统计所有文章中出现的词的位置标识，对应着列表中的单词(单个字母不统计,不支持中文,需要使用jieba分词)，</span></span><br><span class="line">    <span class="comment"># X 文本或者包含文本字符串的可迭代对象</span></span><br><span class="line">    <span class="comment"># 返回值: 返回sparse矩阵</span></span><br><span class="line">    CountVectorizer.fit_transform(X)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># X： array数据或者sparse矩阵</span></span><br><span class="line">    <span class="comment"># 返回值：转换之前的数据格式</span></span><br><span class="line">    CountVetorizer.inverse_transform(X)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 返回值: 单词列表</span></span><br><span class="line">    CountVetorizer.get_feature_names()</span><br></pre></td></tr></table></figure>
<h4 id="为什么需要这"><a class="markdownIt-Anchor" href="#为什么需要这">#</a> 为什么需要这</h4>
<p>分类机器学习算法的应用基础。</p>
<h4 id="应用"><a class="markdownIt-Anchor" href="#应用">#</a> 应用</h4>
<ul>
<li>文本分类</li>
<li>情感分析</li>
</ul>
<h4 id="数据的预处理"><a class="markdownIt-Anchor" href="#数据的预处理">#</a> 数据的预处理</h4>
<p>通过特定的统计方法 (数学方法), 将数据转换成算法要求的数据。</p>
<h5 id="数据处理的方法"><a class="markdownIt-Anchor" href="#数据处理的方法">#</a> 数据处理的方法</h5>
<p>API:<br>
 在 sklearn.preprocessing 中。</p>
<ul>
<li>
<p>数值型数据:</p>
<ul>
<li>
<p>标准缩放</p>
<ul>
<li>
<p>归一化:<br>
 通过对原始数据机型交换把数据映射到 (默认 [0,1]) 之间<br>
<img data-src="./images/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0_%E5%BD%92%E4%B8%80%E5%BD%92%E4%B8%80%E5%8C%96%E5%85%AC%E5%BC%8F.png" alt="机器学习_归一归一化公式.png"><br>
 <code> API: MinMaxScalar</code> <br>
 实现归一化的步骤：</p>
<ul>
<li>实例化 <code>MinMaxScalar</code></li>
<li>调用  <code>fit_transform</code>  进行转换</li>
</ul>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mm = MinMaxScalar(feature_range=(<span class="number">2</span>,<span class="number">3</span>))</span><br><span class="line">data = mm.fit_transform([[],[],[]])</span><br><span class="line"><span class="built_in">print</span>(data)</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>标准化<br>
通过对原始数据进行变换把数据变换到均值为 0，标准差为 1 的范围内。<br>
<img data-src="./images/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0_%E6%A0%87%E5%87%86%E5%8C%96%E5%85%AC%E5%BC%8F.png" alt="机器学习_标准化公式"><br>
对于归一化来讲，如果出现了异常点，影响了最大值和最小值，那么结果显然会发生改变.<br>
 对标准化来讲，如果出现异常点，由于具有一定数据量，少量的异常点对平均值的影响并不大，从而方差改变较小。</p>
<p><code>API: StandardScalar(....) </code> <br>
标准化的步骤：</p>
<ul>
<li>实例化 StandardScalar</li>
<li>调用 fit_transfrom</li>
</ul>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#处理之后每列来说所有数据都聚集在均值0附近标准差差为1</span></span><br><span class="line">StandardScalar(...)</span><br><span class="line">    <span class="comment"># X:numpy array格式的数据[n_samples,n_features]</span></span><br><span class="line">    <span class="comment"># 返回值: 转换后的形状相同的array</span></span><br><span class="line">    StandardScalar.fit_transfrom(X)</span><br><span class="line">    <span class="comment"># 原始数据中每列特征的平均值</span></span><br><span class="line">    StandardScalar.mean_</span><br><span class="line">    <span class="comment"># 原始数据每列特征的方差</span></span><br><span class="line">    StandardScalar.std_</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>缺失值<br>
处理缺失值的方法:</p>
<ul>
<li>删除</li>
<li>插补</li>
</ul>
</li>
</ul>
<p>插补使用的是:  <code>Imputer</code>  方法</p>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 完成缺失值插补</span></span><br><span class="line">Imputer(miss_values=<span class="string">&#x27;NaN&#x27;</span>,strategy=<span class="string">&#x27;mean&#x27;</span>,axis=<span class="number">0</span>)</span><br><span class="line">    <span class="comment"># X: numpy array格式的数据[n_samples,n_features]</span></span><br><span class="line">    <span class="comment"># 返回值: 转换后的形状相同的array</span></span><br><span class="line">    Imputer.fit_transform(X)</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li>
<p>类别型数据</p>
<ul>
<li>one-hot 编码</li>
</ul>
</li>
<li>
<p>时间类型</p>
<ul>
<li>时间的拆分</li>
</ul>
</li>
</ul>
<h3 id="数据的降维"><a class="markdownIt-Anchor" href="#数据的降维">#</a> 数据的降维</h3>
<p>降维指的是降的是特征的维度 (特征的数量)。<br>
两种方式：特征选择 和 主成分分析</p>
<h4 id="特征选择的原因"><a class="markdownIt-Anchor" href="#特征选择的原因">#</a> 特征选择的原因</h4>
<ul>
<li>冗余：部分特征的相关度高，容易消耗计算机性能</li>
<li>噪声：部分特征会对结果产生影响</li>
</ul>
<h4 id="特征选择是什么"><a class="markdownIt-Anchor" href="#特征选择是什么">#</a> 特征选择是什么？</h4>
<p>就是单纯的从提取到的所有特征中选择部分特征作为训练集特征，特征在选择前后可以改变值，也可以不改变值。但是选择后的特征维数肯定比选择前小，毕竟我们只选择了其中一部分特征。<br>
主要方法有:</p>
<ul>
<li>filter (过滤式): varianceThreshold</li>
<li>Embedde (嵌入式): 正则化，决策树</li>
<li>Wrapper (包裹式)</li>
<li>神经网络</li>
</ul>
<p>API:  <code> sklearn.feature_selection.VarianceThreshold</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 删除所有低方差特征</span></span><br><span class="line">VarianceThreshold(threhold=<span class="number">0.0</span>)</span><br><span class="line">    <span class="comment"># X: numpy array格式的数据[n_samples,n_features]</span></span><br><span class="line">    <span class="comment"># 返回值: 训练集差异地域threshold的特征将被删除</span></span><br><span class="line">    <span class="comment"># 默认值是保留所有非零方差特征,即删除所有样本中具有相同值的特征</span></span><br><span class="line">    Variance.fit_transform(X)</span><br></pre></td></tr></table></figure>
<h3 id="pca-分析简化数据集的技术"><a class="markdownIt-Anchor" href="#pca-分析简化数据集的技术">#</a> PCA 分析简化数据集的技术</h3>
<p>目的是： 数据维度压缩，尽可能降低原数据的维度 (复杂度), 损失少量信息<br>
作用：可以削减回归分析或者聚类分析中特征的数量。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将数据分解为较低维数的空间</span></span><br><span class="line">PCA(n_components=<span class="literal">None</span>)</span><br><span class="line">    <span class="comment"># X: numpy array格式的数据[n_samples,n_features]</span></span><br><span class="line">    <span class="comment"># 返回值: 转化后制定维度的array</span></span><br><span class="line">    PCA.fit_transform(X)</span><br></pre></td></tr></table></figure>
<h2 id="机器学习算法基础"><a class="markdownIt-Anchor" href="#机器学习算法基础">#</a> 机器学习算法基础</h2>
<h3 id="监督学习supervised-learnning"><a class="markdownIt-Anchor" href="#监督学习supervised-learnning">#</a> 监督学习：supervised learnning</h3>
<p>输入数据由输入特征值 和 目标值组成。</p>
<p>目标值连续则是回归问题， 目标值离散则是分类问题。</p>
<h3 id="无监督学习-unsupervised-learning"><a class="markdownIt-Anchor" href="#无监督学习-unsupervised-learning">#</a> 无监督学习. unsupervised learning</h3>
<p>输入数据并未进行标记，没有目标值。 =&gt; 聚类 (kmeans)</p>
<h3 id="半监督学习-semi-supervised-learning"><a class="markdownIt-Anchor" href="#半监督学习-semi-supervised-learning">#</a> 半监督学习： semi-supervised learning</h3>
<p>训练集同时包含有标记样本数据 和 未标记样本数据</p>
<h3 id="强化学习-reinforcement-learning"><a class="markdownIt-Anchor" href="#强化学习-reinforcement-learning">#</a> 强化学习: reinforcement learning</h3>
<p>本质是 make decisions 问题，即自动决策问题，并且可以做连续决策。</p>
<p>没有训练数据，建立模型的时候人为设定好可以操作的规则，不断自我尝试，自己去探索。</p>
<p>强化学习的目标就是获取更多的累计奖励。</p>
<p>举个例子:</p>
<p>小孩子想要走路，但是在这之前，他需要先站起来，站起来之后还要保持平衡，接下来就要先迈出一条腿，是左腿还是右腿，迈出一步还要迈出下一步。</p>
<p>小孩子就是 agent，他试图通过 行动 (即行走) 来模型环境 (行走的表面) 并且从一个状态转变到另一个状态 (即他走的每一步)，当他完成了任务的子任务（即走了几步) 时，孩子收到奖励，并且当他不能走路时，就不会给奖励。</p>
<p>主要包含四个元素: agent  行动 环境  奖励</p>
<p><img data-src="./images/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%88%86%E7%B1%BB.png" alt=""></p>
<h2 id="最后"><a class="markdownIt-Anchor" href="#最后">#</a> 最后</h2>
<p>期望和你一起遇见更好的自己</p>
<p><img data-src="/images/rocketmq/qrcode.jpg" alt=""></p>

      <div class="tags">
          <a href="/tags/MachineLearn/" rel="tag"><i class="ic i-tag"></i> MachineLearn</a>
      </div>
  </div>

   <footer>

    <div class="meta">
  <span class="item">
    <span class="icon">
      <i class="ic i-calendar-check"></i>
    </span>
    <span class="text">更新于</span>
    <time title="修改时间：2021-11-11 21:42:06" itemprop="dateModified" datetime="2021-11-11T21:42:06+08:00">2021-11-11</time>
  </span>
  <span id="2021/10/28/machine-learn/机器学习01-简单介绍和了解/" class="item leancloud_visitors" data-flag-title="机器学习 - 简介" title="阅读次数">
      <span class="icon">
        <i class="ic i-eye"></i>
      </span>
      <span class="text">阅读次数</span>
      <span class="leancloud-visitors-count"></span>
      <span class="text">次</span>
  </span>
</div>

      
<div class="reward">
  <button><i class="ic i-heartbeat"></i> 支持一下</button>
  <p>请我喝[咖啡]~(￣▽￣)~*</p>
  <div id="qr">
      
      <div>
        <img data-src="/images/wechatpay.png" alt="方小白 微信支付">
        <p>微信支付</p>
      </div>
      
      <div>
        <img data-src="/images/alipay.png" alt="方小白 支付宝">
        <p>支付宝</p>
      </div>
      <div>
        <img data-src="/images/numberpay.jpg" alt="方小白 numberpay">
        <p>numberpay</p>
      </div>
  </div>
</div>

      

<div id="copyright">
<ul>
  <li class="author">
    <strong>本文作者： </strong>方小白 <i class="ic i-at"><em>@</em></i>方家小白
  </li>
  <li class="link">
    <strong>本文链接：</strong>
    <a href="https://fangjiaxiaobai.github.io/2021/10/28/machine-learn/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A001-%E7%AE%80%E5%8D%95%E4%BB%8B%E7%BB%8D%E5%92%8C%E4%BA%86%E8%A7%A3/" title="机器学习 - 简介">https://fangjiaxiaobai.github.io/2021/10/28/machine-learn/机器学习01-简单介绍和了解/</a>
  </li>
  <li class="license">
    <strong>版权声明： </strong>本站所有文章除特别声明外，均采用 <span class="exturl" data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC9kZWVkLnpo"><i class="ic i-creative-commons"><em>(CC)</em></i>BY-NC-SA</span> 许可协议。转载请注明出处！
  </li>
</ul>
</div>

  </footer>

</article>

  </div>
  

<div class="post-nav">
    <div class="item left">
      

  <a href="/2021/10/18/BQ/hdoj/HD-1005/" itemprop="url" rel="prev" data-background-image="https:&#x2F;&#x2F;tva2.sinaimg.cn&#x2F;mw690&#x2F;6833939bly1gipey84bjtj20zk0m8hdt.jpg" title="1005 Number Sequence">
  <span class="type">上一篇</span>
  <span class="category"><i class="ic i-flag"></i> 杭电 Oj</span>
  <h3>1005 Number Sequence</h3>
  </a>

    </div>
    <div class="item right">
      

  <a href="/2021/10/29/machine-learn/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A002-K-%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%95/" itemprop="url" rel="next" data-background-image="https:&#x2F;&#x2F;tva2.sinaimg.cn&#x2F;mw690&#x2F;6833939bly1gipey0a334j20zk0m8qpt.jpg" title="K-近邻算法(KNN)">
  <span class="type">下一篇</span>
  <span class="category"><i class="ic i-flag"></i> MachineLearn</span>
  <h3>K-近邻算法(KNN)</h3>
  </a>

    </div>
</div>

  
  <div class="wrap" id="comments"></div>


        </div>
        <div id="sidebar">
          

<div class="inner">

  <div class="panels">
    <div class="inner">
      <div class="contents panel pjax" data-title="文章目录">
          <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A6%82%E8%BF%B0"><span class="toc-number">1.</span> <span class="toc-text"> 概述</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0"><span class="toc-number">1.1.</span> <span class="toc-text"> 什么是机器学习</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E9%9C%80%E8%A6%81%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0"><span class="toc-number">1.2.</span> <span class="toc-text"> 为什么需要机器学习</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF"><span class="toc-number">1.3.</span> <span class="toc-text"> 机器学习的应用场景</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B"><span class="toc-number">2.</span> <span class="toc-text"> 机器学习的工作流程</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E9%9B%86%E7%9A%84%E7%BB%93%E6%9E%84"><span class="toc-number">3.</span> <span class="toc-text"> 数据集的结构</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8F%AF%E7%94%A8%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">3.1.</span> <span class="toc-text"> 可用的数据集</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B8%B8%E7%94%A8%E6%95%B0%E6%8D%AE%E9%9B%86%E6%95%B0%E6%8D%AE%E7%9A%84%E7%BB%93%E6%9E%84%E7%BB%84%E6%88%90"><span class="toc-number">3.2.</span> <span class="toc-text"> 常用数据集数据的结构组成</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E5%88%86%E5%89%B2"><span class="toc-number">3.3.</span> <span class="toc-text"> 数据分割</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E7%9A%84%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B"><span class="toc-number">4.</span> <span class="toc-text"> 数据的特征工程</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E7%89%B9%E5%BE%81%E6%98%AF%E4%BB%80%E4%B9%88"><span class="toc-number">4.1.</span> <span class="toc-text"> 数据特征是什么</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B%E7%9A%84%E6%84%8F%E4%B9%89"><span class="toc-number">4.2.</span> <span class="toc-text"> 特征工程的意义</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%89%B9%E5%BE%81%E6%8A%BD%E5%8F%96%E5%AE%9E%E4%BE%8B%E6%BC%94%E7%A4%BA"><span class="toc-number">4.2.1.</span> <span class="toc-text"> 特征抽取实例演示</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%89%B9%E5%BE%81%E6%8A%BD%E5%8F%96api"><span class="toc-number">4.2.2.</span> <span class="toc-text"> 特征抽取 API</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8%E6%B5%81%E7%A8%8B"><span class="toc-number">4.2.2.1.</span> <span class="toc-text"> 使用流程</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AD%97%E5%85%B8%E6%95%B0%E6%8D%AE%E6%8F%90%E5%8F%96%E7%9A%84%E7%8E%B0%E8%B1%A1"><span class="toc-number">4.2.3.</span> <span class="toc-text"> 字典数据提取的现象:</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BD%9C%E7%94%A8-%E5%AF%B9%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E8%BF%9B%E8%A1%8C%E7%89%B9%E5%BE%81%E5%80%BC%E5%8C%96"><span class="toc-number">4.2.4.</span> <span class="toc-text"> 作用：对文本数据进行特征值化</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%B1%BB-sklearnfeature_extractiontextcountvectorizer"><span class="toc-number">4.2.5.</span> <span class="toc-text"> 类: sklearn.feature_extraction.text.CountVectorizer</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#api"><span class="toc-number">4.2.6.</span> <span class="toc-text"> API</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%B1%BB-sklearnfeature_extractiontexttfidfvectorizer"><span class="toc-number">4.2.7.</span> <span class="toc-text"> 类  sklearn.feature_extraction.text.TfidfVectorizer </span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E9%9C%80%E8%A6%81%E8%BF%99"><span class="toc-number">4.2.8.</span> <span class="toc-text"> 为什么需要这</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%BA%94%E7%94%A8"><span class="toc-number">4.2.9.</span> <span class="toc-text"> 应用</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E7%9A%84%E9%A2%84%E5%A4%84%E7%90%86"><span class="toc-number">4.2.10.</span> <span class="toc-text"> 数据的预处理</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E7%9A%84%E6%96%B9%E6%B3%95"><span class="toc-number">4.2.10.1.</span> <span class="toc-text"> 数据处理的方法</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E7%9A%84%E9%99%8D%E7%BB%B4"><span class="toc-number">4.3.</span> <span class="toc-text"> 数据的降维</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9%E7%9A%84%E5%8E%9F%E5%9B%A0"><span class="toc-number">4.3.1.</span> <span class="toc-text"> 特征选择的原因</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9%E6%98%AF%E4%BB%80%E4%B9%88"><span class="toc-number">4.3.2.</span> <span class="toc-text"> 特征选择是什么？</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#pca-%E5%88%86%E6%9E%90%E7%AE%80%E5%8C%96%E6%95%B0%E6%8D%AE%E9%9B%86%E7%9A%84%E6%8A%80%E6%9C%AF"><span class="toc-number">4.4.</span> <span class="toc-text"> PCA 分析简化数据集的技术</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E5%9F%BA%E7%A1%80"><span class="toc-number">5.</span> <span class="toc-text"> 机器学习算法基础</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0supervised-learnning"><span class="toc-number">5.1.</span> <span class="toc-text"> 监督学习：supervised learnning</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-unsupervised-learning"><span class="toc-number">5.2.</span> <span class="toc-text"> 无监督学习. unsupervised learning</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-semi-supervised-learning"><span class="toc-number">5.3.</span> <span class="toc-text"> 半监督学习： semi-supervised learning</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0-reinforcement-learning"><span class="toc-number">5.4.</span> <span class="toc-text"> 强化学习: reinforcement learning</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9C%80%E5%90%8E"><span class="toc-number">6.</span> <span class="toc-text"> 最后</span></a></li></ol>
      </div>
      <div class="related panel pjax" data-title="系列文章">
        <ul>
          <li class="active"><a href="/2021/10/28/machine-learn/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A001-%E7%AE%80%E5%8D%95%E4%BB%8B%E7%BB%8D%E5%92%8C%E4%BA%86%E8%A7%A3/" rel="bookmark" title="机器学习-简介">机器学习-简介</a></li><li><a href="/2021/10/29/machine-learn/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A002-K-%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%95/" rel="bookmark" title="K-近邻算法(KNN)">K-近邻算法(KNN)</a></li><li><a href="/2021/11/17/machine-learn/Model-evaluation/02-confusion_matrix/" rel="bookmark" title="模型评估之 分类模型的评估指标">模型评估之 分类模型的评估指标</a></li><li><a href="/2021/11/17/machine-learn/Model-evaluation/01-overview/" rel="bookmark" title="模型评估概述">模型评估概述</a></li>
        </ul>
      </div>
      <div class="overview panel" data-title="站点概览">
        <div class="author" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <img class="image" itemprop="image" alt="方小白"
      data-src="/images/avatar.jpg">
  <p class="name" itemprop="name">方小白</p>
  <div class="description" itemprop="description">和你一起遇见更好的自己</div>
</div>

<nav class="state">
    <div class="item posts">
      <a href="/archives/">
        <span class="count">92</span>
        <span class="name">文章</span>
      </a>
    </div>
    <div class="item categories">
      <a href="/categories/">
        <span class="count">15</span>
        <span class="name">分类</span>
      </a>
    </div>
    <div class="item tags">
      <a href="/tags/">
        <span class="count">52</span>
        <span class="name">标签</span>
      </a>
    </div>
</nav>

<div class="social">
      <span class="exturl item github" data-url="aHR0cHM6Ly9naXRodWIuY29tL2ZhbmdqaWF4aWFvYmFp" title="https:&#x2F;&#x2F;github.com&#x2F;fangjiaxiaobai"><i class="ic i-github"></i></span>
      <span class="exturl item twitter" data-url="aHR0cHM6Ly90d2l0dGVyLmNvbS9mYW5namlheGlhb2JhaQ==" title="https:&#x2F;&#x2F;twitter.com&#x2F;fangjiaxiaobai"><i class="ic i-twitter"></i></span>
      <span class="exturl item zhihu" data-url="aHR0cHM6Ly93d3cuemhpaHUuY29tL3Blb3BsZS9mYW5namlheGlhb2JhaQ==" title="https:&#x2F;&#x2F;www.zhihu.com&#x2F;people&#x2F;fangjiaxiaobai"><i class="ic i-zhihu"></i></span>
      <span class="exturl item music" data-url="aHR0cHM6Ly9tdXNpYy4xNjMuY29tLyMvdXNlci9ob21lP2lkPTc3NDY2OTM3" title="https:&#x2F;&#x2F;music.163.com&#x2F;#&#x2F;user&#x2F;home?id&#x3D;77466937"><i class="ic i-cloud-music"></i></span>
      <span class="exturl item email" data-url="bWFpbHRvOmZhbmdqaWF4aWFvYmFpQDE2My5jb20=" title="mailto:fangjiaxiaobai@163.com"><i class="ic i-envelope"></i></span>
</div>

<ul class="menu">
  
    
  <li class="item">
    <a href="/" rel="section"><i class="ic i-home"></i>首页</a>
  </li>

        
  <li class="item dropdown">
      <a href="javascript:void(0);"><i class="ic i-feather"></i>文章</a>
    <ul class="submenu">

        
  <li class="item">
    <a href="/archives/" rel="section"><i class="ic i-list-alt"></i>归档</a>
  </li>

        
  <li class="item">
    <a href="/categories/" rel="section"><i class="ic i-th"></i>分类</a>
  </li>

        
  <li class="item">
    <a href="/tags/" rel="section"><i class="ic i-tags"></i>标签</a>
  </li>

  </ul>
        
  <li class="item dropdown">
      <a href="javascript:void(0);"><i class="ic i-magic"></i>系列</a>
    <ul class="submenu">

        
  <li class="item">
    <a href="/series/leetcode" rel="section"><i class="ic i-music"></i>LeetCode系列</a>
  </li>

        
  <li class="item">
    <a href="/series/MySQL" rel="section"><i class="ic i-sakura"></i>MySQL系列</a>
  </li>

        
  <li class="item">
    <a href="/series/Redis" rel="section"><i class="ic i-snapchat-ghost"></i>Redis系列</a>
  </li>

        
  <li class="item">
    <a href="/series/Netty" rel="section"><i class="ic i-clipboard"></i>Netty系列</a>
  </li>

        
  <li class="item">
    <a href="/series/java" rel="section"><i class="ic i-coffee"></i>Java系列</a>
  </li>

        
  <li class="item">
    <a href="/series/git" rel="section"><i class="ic i-link-alt"></i>Git系列</a>
  </li>

  </ul>
    
  <li class="item">
    <a href="/links" rel="section"><i class="ic i-magic"></i>链接</a>
  </li>

        
  <li class="item dropdown">
      <a href="javascript:void(0);"><i class="ic i-chart-area"></i>推广</a>
    <ul class="submenu">

        
  <li class="item">
    <a href="/promotions/geekbang" rel="section"><i class="ic i-envelope"></i>极客时间</a>
  </li>

        
  <li class="item">
    <a href="/promotions/vpn" rel="section"><i class="ic i-thumbtack"></i>科学上网</a>
  </li>

        
  <li class="item">
    <a href="/promotions/common" rel="section"><i class="ic i-times"></i>书籍资料</a>
  </li>

  </ul>
        
  <li class="item dropdown">
      <a href="javascript:void(0);"><i class="ic i-user"></i>关于</a>
    <ul class="submenu">

        
  <li class="item">
    <a href="/about/me" rel="section"><i class="ic i-user"></i>关于我</a>
  </li>

        
  <li class="item">
    <a href="/about/love" rel="section"><i class="ic i-heart"></i>关于她</a>
  </li>

  </ul>

</ul>

      </div>
    </div>
  </div>

  <ul id="quick">
    <li class="prev pjax">
        <a href="/2021/10/18/BQ/hdoj/HD-1005/" rel="prev" title="上一篇"><i class="ic i-chevron-left"></i></a>
    </li>
    <li class="up"><i class="ic i-arrow-up"></i></li>
    <li class="down"><i class="ic i-arrow-down"></i></li>
    <li class="next pjax">
        <a href="/2021/10/29/machine-learn/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A002-K-%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%95/" rel="next" title="下一篇"><i class="ic i-chevron-right"></i></a>
    </li>
    <li class="percent"></li>
  </ul>
</div>


        </div>
        <div class="dimmer"></div>
      </div>
    </main>
    <footer id="footer">
      <div class="inner">
        <div class="widgets">
          
<div class="rpost pjax">
  <h2>随机文章</h2>
  <ul>
      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/" title="分类于 数据结构与算法">数据结构与算法</a>
</div>

    <span><a href="/2021/09/01/dataStructuresAndAlgorithms/hash/%E7%AE%97%E6%B3%9502-%E5%93%88%E5%B8%8C%E7%AE%97%E6%B3%95/" title="哈希算法">哈希算法</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/LeetCode%E7%B3%BB%E5%88%97/" title="分类于 LeetCode 系列">LeetCode 系列</a>
</div>

    <span><a href="/2021/08/19/BQ/LeetCode/0001-%E5%8F%8D%E8%BD%AC%E6%95%B0%E7%BB%84/" title="LC:反转数组">LC:反转数组</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/%E6%90%9C%E7%B4%A2%E4%B9%8BEs/" title="分类于 搜索之 Es">搜索之 Es</a>
</div>

    <span><a href="/2021/08/31/es-series/README/" title="Elastic Search 目录">Elastic Search 目录</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/Redis%E6%95%B0%E6%8D%AE%E5%BA%93/" title="分类于 Redis 数据库">Redis 数据库</a>
</div>

    <span><a href="/2021/08/01/Redis%E7%B3%BB%E5%88%97/B-7-Redis%E7%9A%84%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E4%B9%8BHyperLogLogs/" title="Redis数据结构之 &#96;HyperLogLogs&#96;">Redis数据结构之 `HyperLogLogs`</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/" title="分类于 数据结构与算法">数据结构与算法</a>
</div>

    <span><a href="/2021/09/01/dataStructuresAndAlgorithms/sort/%E7%AE%97%E6%B3%9503-%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F/" title="归并排序">归并排序</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/%E6%9D%AD%E7%94%B5Oj/" title="分类于 杭电 Oj">杭电 Oj</a>
</div>

    <span><a href="/2021/10/13/BQ/hdoj/HD-1000/" title="1000 A + B Problem">1000 A + B Problem</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/MySQL%E6%95%B0%E6%8D%AE%E5%BA%93/" title="分类于 MySQL 数据库">MySQL 数据库</a>
</div>

    <span><a href="/2021/07/24/MySQL%E7%B3%BB%E5%88%97/%E6%95%B0%E6%8D%AE%E5%BA%931-01.%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E7%89%88%E6%9C%AC/" title="MySQL数据库的版本">MySQL数据库的版本</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/git%E7%B3%BB%E5%88%97/" title="分类于 git 系列">git 系列</a>
</div>

    <span><a href="/2021/07/18/git%E7%B3%BB%E5%88%97/14-git%E5%85%B6%E4%BB%96%E5%91%BD%E4%BB%A4/" title="其他命令">其他命令</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/LeetCode%E7%B3%BB%E5%88%97/" title="分类于 LeetCode 系列">LeetCode 系列</a>
</div>

    <span><a href="/2021/11/02/BQ/LeetCode/0237-delete-node-in-a-linked-list/" title="LC:237.删除链表中的节点">LC:237.删除链表中的节点</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/Redis%E6%95%B0%E6%8D%AE%E5%BA%93/" title="分类于 Redis 数据库">Redis 数据库</a>
</div>

    <span><a href="/2021/07/23/Redis%E7%B3%BB%E5%88%97/00-%E5%89%8D%E8%A8%80/" title="Redis 开篇杂谈">Redis 开篇杂谈</a></span>
  </li>

  </ul>
</div>
<div>
  <h2>最新评论</h2>
  <ul class="leancloud-recent-comment"></ul>
</div>

        </div>
        <div class="status">
  <div class="copyright">
    
    &copy; 
    <span itemprop="copyrightYear">2021</span>
    <span class="with-love">
      <i class="ic i-sakura rotate"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">方小白 @ 方家小白</span>
  </div>
  <div class="count">
    <span class="post-meta-item-icon">
      <i class="ic i-chart-area"></i>
    </span>
    <span title="站点总字数">389k 字</span>

    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="ic i-coffee"></i>
    </span>
    <span title="站点阅读时长">5:53</span>
  </div>
  <div class="powered-by">
    基于 <span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlv">Hexo</span> & Theme.<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2FtZWhpbWUvaGV4by10aGVtZS1zaG9rYQ==">Shoka</span>
  </div>
</div>

      </div>
    </footer>
  </div>
<script data-config type="text/javascript">
  var LOCAL = {
    path: '2021/10/28/machine-learn/机器学习01-简单介绍和了解/',
    favicon: {
      show: "方家小白",
      hide: "方家小白"
    },
    search : {
      placeholder: "文章搜索",
      empty: "关于 「 ${query} 」，什么也没搜到",
      stats: "${time} ms 内找到 ${hits} 条结果"
    },
    valine: true,fancybox: true,copyright: '复制成功，转载请遵守 <i class="ic i-creative-commons"></i>BY-NC-SA 协议。',
    ignores : [
      function(uri) {
        return uri.includes('#');
      },
      function(uri) {
        return new RegExp(LOCAL.path+"$").test(uri);
      }
    ]
  };
</script>

<script src="https://cdn.polyfill.io/v2/polyfill.js"></script>

<script src="//cdn.jsdelivr.net/combine/npm/pace-js@1.0.2/pace.min.js,npm/pjax@0.2.8/pjax.min.js,npm/whatwg-fetch@3.4.0/dist/fetch.umd.min.js,npm/animejs@3.2.0/lib/anime.min.js,npm/algoliasearch@4/dist/algoliasearch-lite.umd.js,npm/instantsearch.js@4/dist/instantsearch.production.min.js,npm/lozad@1/dist/lozad.min.js,npm/quicklink@2/dist/quicklink.umd.js"></script>

<script src="/js/app.js?v=0.2.5"></script>




</body>
</html>
