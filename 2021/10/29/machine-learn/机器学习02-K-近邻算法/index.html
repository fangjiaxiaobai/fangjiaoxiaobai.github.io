



<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#FFF"> 
<meta http-equiv="Content-Security-Policy" content="upgrade-insecure-requests">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">

<link rel="icon" type="image/ico" sizes="32x32" href="/images/favicon.ico">
  <meta http-equiv="Cache-Control" content="no-transform">
  <meta http-equiv="Cache-Control" content="no-siteapp">


<link rel="alternate" type="application/rss+xml" title="方家小白" href="https://fangjiaxiaobai.github.io/rss.xml" />
<link rel="alternate" type="application/atom+xml" title="方家小白" href="https://fangjiaxiaobai.github.io/atom.xml" />
<link rel="alternate" type="application/json" title="方家小白" href="https://fangjiaxiaobai.github.io/feed.json" />

<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Mulish:300,300italic,400,400italic,700,700italic%7CFredericka%20the%20Great:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20JP:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20SC:300,300italic,400,400italic,700,700italic%7CInconsolata:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="/css/app.css?v=0.2.5">

  
  <meta name="keywords" content="MachineLearn,KNN" />


<link rel="canonical" href="https://fangjiaxiaobai.github.io/2021/10/29/machine-learn/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A002-K-%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%95/">



  <title>
K - 近邻算法 (KNN) - MachineLearn |
方家小白 = 和你一起遇见更好的自己</title>
<meta name="generator" content="Hexo 5.4.0"></head>
<body itemscope itemtype="http://schema.org/WebPage">
  <div id="loading">
    <div class="cat">
      <div class="body"></div>
      <div class="head">
        <div class="face"></div>
      </div>
      <div class="foot">
        <div class="tummy-end"></div>
        <div class="bottom"></div>
        <div class="legs left"></div>
        <div class="legs right"></div>
      </div>
      <div class="paw">
        <div class="hands left"></div>
        <div class="hands right"></div>
      </div>
    </div>
  </div>
  <div id="container">
    <header id="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="inner">
        <div id="brand">
          <div class="pjax">
          
  <h1 itemprop="name headline">K - 近邻算法 (KNN)
  </h1>
  
<div class="meta">
  <span class="item" title="创建时间：2021-10-29 18:18:00">
    <span class="icon">
      <i class="ic i-calendar"></i>
    </span>
    <span class="text">发表于</span>
    <time itemprop="dateCreated datePublished" datetime="2021-10-29T18:18:00+08:00">2021-10-29</time>
  </span>
  <span class="item" title="本文字数">
    <span class="icon">
      <i class="ic i-pen"></i>
    </span>
    <span class="text">本文字数</span>
    <span>9.7k</span>
    <span class="text">字</span>
  </span>
  <span class="item" title="阅读时长">
    <span class="icon">
      <i class="ic i-clock"></i>
    </span>
    <span class="text">阅读时长</span>
    <span>9 分钟</span>
  </span>
</div>


          </div>
        </div>
        <nav id="nav">
  <div class="inner">
    <div class="toggle">
      <div class="lines" aria-label="切换导航栏">
        <span class="line"></span>
        <span class="line"></span>
        <span class="line"></span>
      </div>
    </div>
    <ul class="menu">
      <li class="item title"><a href="/" rel="start">方家小白</a></li>
    </ul>
    <ul class="right">
      <li class="item theme">
        <i class="ic i-sun"></i>
      </li>
      <li class="item search">
        <i class="ic i-search"></i>
      </li>
    </ul>
  </div>
</nav>

      </div>
      <div id="imgs" class="pjax">
        <ul>
          <li class="item" data-background-image="https://tva1.sinaimg.cn/large/6833939bly1gicit31ffoj20zk0m8naf.jpg"></li>
          <li class="item" data-background-image="https://tva1.sinaimg.cn/large/6833939bly1gipexoj0moj20zk0m8kgu.jpg"></li>
          <li class="item" data-background-image="https://tva1.sinaimg.cn/large/6833939bly1gipesng5oej20zk0m87d4.jpg"></li>
          <li class="item" data-background-image="https://tva1.sinaimg.cn/large/6833939bly1giph4baakhj20zk0m8h5q.jpg"></li>
          <li class="item" data-background-image="https://tva1.sinaimg.cn/large/6833939bly1giciundwu5j20zk0m8n9e.jpg"></li>
          <li class="item" data-background-image="https://tva1.sinaimg.cn/large/6833939bly1gipetv6p75j20zk0m8x6p.jpg"></li>
        </ul>
      </div>
    </header>
    <div id="waves">
      <svg class="waves" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto">
        <defs>
          <path id="gentle-wave" d="M-160 44c30 0 58-18 88-18s 58 18 88 18 58-18 88-18 58 18 88 18 v44h-352z" />
        </defs>
        <g class="parallax">
          <use xlink:href="#gentle-wave" x="48" y="0" />
          <use xlink:href="#gentle-wave" x="48" y="3" />
          <use xlink:href="#gentle-wave" x="48" y="5" />
          <use xlink:href="#gentle-wave" x="48" y="7" />
        </g>
      </svg>
    </div>
    <main>
      <div class="inner">
        <div id="main" class="pjax">
          
  <div class="article wrap">
    
<div class="breadcrumb" itemscope itemtype="https://schema.org/BreadcrumbList">
<i class="ic i-home"></i>
<span><a href="/">首页</a></span><i class="ic i-angle-right"></i>
<span  class="current" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/MachineLearn/" itemprop="item" rel="index" title="分类于 MachineLearn"><span itemprop="name">MachineLearn</span></a>
<meta itemprop="position" content="1" /></span>
</div>

    <article itemscope itemtype="http://schema.org/Article" class="post block" lang="zh-CN">
  <link itemprop="mainEntityOfPage" href="https://fangjiaxiaobai.github.io/2021/10/29/machine-learn/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A002-K-%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%95/">

  <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="image" content="/images/avatar.jpg">
    <meta itemprop="name" content="方小白">
    <meta itemprop="description" content="和你一起遇见更好的自己, 和你一起遇见更好的自己">
  </span>

  <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="方家小白">
  </span>

  <div class="body md" itemprop="articleBody">
    

    <div id="fxb_container" class="fxb_container_style">
      <p><code>k-近邻算法</code> ，英文名:  <code>K Nearest Neighbor</code>  算法  又叫 <code>KNN算法</code> ，这个算法是机器学习里面一个比较经典的算法， 总体来说 1 算法是相对比较容易理解的算法.</p>
<h2 id="定义"><a class="markdownIt-Anchor" href="#定义">#</a> 定义</h2>
<p>如果一个样本在特征空间中的 k 个最相似 (即特征空间中最邻近) 的样本中的大多数属于某一个类别，则该样本也属于这个类别。</p>
<blockquote>
<p><code>KNN</code>  算法最早是由 <code>Cover</code>  和 <code>Hart</code>  提出的一种分类算法。应用场景有字符识别、文本分类、图像识别等领域。</p>
</blockquote>
<h2 id="算法的理解"><a class="markdownIt-Anchor" href="#算法的理解">#</a> 算法的理解</h2>
<p>举一个例子来，来分析一下  <code>KNN</code>  算法的实现原理</p>
<p>假设我们现在有几部电影，如下图:</p>
<p><img data-src="/images/ml/02-knn-1.png" alt=""></p>
<p>我们要 根据 搞笑镜头，拥抱镜头，打斗镜头的个数 这三个特征来预测出 《唐人街探案》所属的电影类型.</p>
<p>我们使用  <code>KNN算法</code>  思想来实现预测。</p>
<p>将样本中特征作为坐标抽，建立坐标系。从而建立特征空间。本例中，分别把 搞笑镜头，拥抱镜头，打斗镜头 作为 <code>x,y,z</code>  轴。然后把计算出每个样本和 《唐人街探案》 的距离，选择距离最近的前 k 个 ( <code>KNN中的k</code> ) 样本，这 <code>k</code>  个样本大多数所属的电影类别就是 《唐人街探案》的电影类型。</p>
<blockquote>
<p>特征空间：是指已特征为坐标轴简历的一种特征的坐标系，可能是多维的。</p>
</blockquote>
<p>那你可能对 距离 是如何计算的，有点疑惑。计算距离的方式有很多种。<br>
先学习一下最简单的 欧氏距离。(初中都学过的！)</p>
<p>在二维坐标系中， 我们可以使用一下方式来计算出两个点的距离。</p>
<p><img data-src="/images/ml/02-knn-2.png" alt=""></p>
<p>在多维的特征空间中，我们也可以使用同样的方式来计算欧式距离。如下图：</p>
<p><img data-src="/images/ml/02-knn-3.png" alt=""></p>
<p>那计算一下样本集中的欧式距离，如下图:</p>
<p><img data-src="/images/ml/02-knn-4.png" alt=""></p>
<p>并计算出了最近的 5 个样本中有三个喜剧片类型，2 两个爱情片类型。 那根据 <code>KNN</code>  就是喜剧片类型。</p>
<p>这就是 <code>KNN算法</code> 的核心思想了。</p>
<p>这个例子中，我们选则了 最近的 <code>5</code>  个样本，也就是 k=5 的时候，会有三个喜剧片类型，两个爱情片类型。这个 <code>5</code>  是如何选择的呢？</p>
<h2 id="k值的选择"><a class="markdownIt-Anchor" href="#k值的选择">#</a> k 值的选择</h2>
<p><code>K值</code> 选择问题，李航博士的一书「统计学习方法」上所说：</p>
<ol>
<li>
<p>选择较小的 <code>K</code>  值，就相当于用较小的领域中的训练实例进行预测，“学习” 近似误差会减小，只有与输入实例较近或相似的训练实例才会对预测结果起作用，与此同时带来的问题是 “学习” 的估计误差会增大，换句话说， <code>K值</code> 的减小就意味着整体模型变得复杂，容易发生过拟合；</p>
</li>
<li>
<p>选择较大的 <code>K值</code> ，就相当于用较大领域中的训练实例进行预测，其优点是可以减少学习的估计误差，但缺点是学习的近似误差会增大。这时候，与输入实例较远（不相似的）训练实例也会对预测器作用，使预测发生错误，且 K 值的增大就意味着整体的模型变得简单。</p>
</li>
<li>
<p><code>K=N</code> （ <code>N</code>  为训练样本个数），则完全不足取，因为此时无论输入实例是什么，都只是简单的预测它属于在训练实例中最多的类，模型过于简单，忽略了训练实例中大量有用信息。</p>
</li>
</ol>
<p>在实际应用中， <code>K值</code> 一般取一个比较小的数值，例如采用交叉验证法 ( <code>cross validation</code> )（简单来说，就是把训练数据在分成两组：训练集和验证集）来选择最优的 K 值。对这个简单的分类器进行泛化，用核方法把这个线性模型扩展到非线性的情况，具体方法是把低维数据集映射到高维特征空间。</p>
<h2 id="knn的优化"><a class="markdownIt-Anchor" href="#knn的优化">#</a> KNN 的优化</h2>
<p><code>KNN</code>  算法需要计算所有的样本数据和预测数据的距离，需要选择出距离预测数据最近的 k 个样本数据的预测归类。在庞大的数据量面前，计算所有样本数据距离，显然是不可取的。为了避免每次都重新计算一遍距离， <code>KNN</code>  算法提供了多种优化方法， 比如  <code>KD-tree</code> ,  <code>ball_tree</code> ,  <code>brute</code> . 这几种优化方式的具体实现逻辑，我会在后面的几篇文章中挨个分析。</p>
<h2 id="距离的计算"><a class="markdownIt-Anchor" href="#距离的计算">#</a> 距离的计算</h2>
<p><code>KNN</code>  算法，最重要的就是距离。 除了上文提到的欧式距离，还有其他计算距离的方法吗？</p>
<p>有。</p>
<p>除了欧式距离，还有 曼哈顿距离，</p>
<h3 id="曼哈顿距离"><a class="markdownIt-Anchor" href="#曼哈顿距离">#</a> 曼哈顿距离</h3>
<p>在曼哈顿街区要从一个十字路口开车到另一个十字路口，驾驶距离显然不是两点间的直线距离。这个实际驾驶距离就是 “曼哈顿距离”。曼哈顿距离也称为 “城市街区距离”( <code>City Block distance</code> )。如下图:<br>
<img data-src="/images/ml/02-knn-6.png" alt=""></p>
<p>计算公式见下图:</p>
<p><img data-src="/images/ml/02-knn-7.png" alt=""></p>
<h3 id="切比雪夫距离-chebyshev-distance"><a class="markdownIt-Anchor" href="#切比雪夫距离-chebyshev-distance">#</a> 切比雪夫距离 (Chebyshev Distance)</h3>
<p>国际象棋中，国王可以直行、横行、斜行，所以国王走一步可以移动到相邻 8 个方格中的任意一个。国王从格子 <code>(x1,y1)</code>  走到格子 <code>(x2,y2)</code>  最少需要多少步？这个距离就叫切比雪夫距离。</p>
<p><img data-src="/images/ml/02-knn-8.png" alt=""></p>
<p>计算公式见下图:</p>
<p><img data-src="/images/ml/02-knn-9.png" alt=""></p>
<h3 id="闵可夫斯基距离minkowski-distance"><a class="markdownIt-Anchor" href="#闵可夫斯基距离minkowski-distance">#</a> 闵可夫斯基距离 (Minkowski Distance)</h3>
<p>闵氏距离不是一种距离，而是一组距离的定义，是对多个距离度量公式的概括性的表述。</p>
<p>两个 n 维变量 <code>a(x11,x12,…,x1n)</code>  与 <code>b(x21,x22,…,x2n)</code>  间的闵可夫斯基距离定义为：</p>
<p><img data-src="/images/ml/02-knn-10.png" alt=""></p>
<p>其中 <code>p</code>  是一个变参数：<br>
当 <code>p=1</code>  时，就是曼哈顿距离；<br>
当 <code>p=2</code>  时，就是欧氏距离；<br>
当 <code>p→∞</code> 时，就是切比雪夫距离。</p>
<p>根据 p 的不同，闵氏距离可以表示某一类 / 种的距离。</p>
<p>小结：<br>
1 闵氏距离，包括曼哈顿距离、欧氏距离和切比雪夫距离都存在明显的缺点:<br>
 <code>e.g.</code>  二维样本 (身高 <code>[单位:cm]</code> , 体重 <code>[单位:kg]</code> ), 现有三个样本： <code>a(180,50)</code> ， <code>b(190,50)</code> ， <code>c(180,60)</code> 。<br>
 <code>a</code>  与 <code>b</code>  的闵氏距离（无论是曼哈顿距离、欧氏距离或切比雪夫距离）等于 <code>a</code>  与 <code>c</code>  的闵氏距离。但实际上身高的 <code>10cm</code>  并不能和体重的 <code>10kg</code>  划等号。</p>
<p>2 闵氏距离的缺点：<br>
​ (1) 将各个分量的量纲 ( <code>scale</code> )，也就是 “单位” 相同的看待了；<br>
​ (2) 未考虑各个分量的分布（期望，方差等）可能是不同的。</p>
<h3 id="标准化欧氏距离-standardized-euclideandistance"><a class="markdownIt-Anchor" href="#标准化欧氏距离-standardized-euclideandistance">#</a> 标准化欧氏距离 (Standardized EuclideanDistance)</h3>
<p>标准化欧氏距离是针对欧氏距离的缺点而作的一种改进。</p>
<p>思路：既然数据各维分量的分布不一样，那先将各个分量都 “标准化” 到均值、方差相等。假设样本集 X 的均值 ( <code>mean</code> ) 为 <code>m</code> ，标准差 ( <code>standard deviation</code> ) 为 <code>s</code> ， <code>X</code>  的 “标准化变量” 表示为：</p>
<p><img data-src="/images/ml/02-knn-11.png" alt=""></p>
<p>如果将方差的倒数看成一个权重，也可称之为加权欧氏距离 ( <code>Weighted Euclidean distance</code> )。</p>
<h3 id="余弦距离cosine-distance"><a class="markdownIt-Anchor" href="#余弦距离cosine-distance">#</a> 余弦距离 (Cosine Distance)</h3>
<p>几何中，夹角余弦可用来衡量两个向量方向的差异；机器学习中，借用这一概念来衡量样本向量之间的差异。</p>
<p>二维空间中向量 <code>A(x1,y1)</code>  与向量 <code>B(x2,y2)</code>  的夹角余弦公式：<br>
<img data-src="/images/ml/02-knn-12.png" alt=""></p>
<p>两个 <code>n</code>  维样本点 <code>a(x11,x12,…,x1n)</code>  和 <code>b(x21,x22,…,x2n)</code>  的夹角余弦为：</p>
<p><img data-src="/images/ml/02-knn-13.png" alt=""></p>
<p>即:</p>
<p><img data-src="/images/ml/02-knn-14.png" alt=""></p>
<p>夹角余弦取值范围为 <code>[-1,1]</code> 。余弦越大表示两个向量的夹角越小，余弦越小表示两向量的夹角越大。当两个向量的方向重合时余弦取最大值 <code>1</code> ，当两个向量的方向完全相反余弦取最小值 <code>-1</code></p>
<h3 id="汉明距离hamming-distance"><a class="markdownIt-Anchor" href="#汉明距离hamming-distance">#</a> 汉明距离 (Hamming Distance)</h3>
<p>两个等长字符串 <code>s1</code>  与 <code>s2</code>  的汉明距离为：将其中一个变为另外一个所需要作的最小字符替换次数。</p>
<p>例如：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">The Hamming distance between &quot;1011101&quot; and &quot;1001001&quot; is 2. </span><br><span class="line">The Hamming distance between &quot;2143896&quot; and &quot;2233796&quot; is 3. </span><br><span class="line">The Hamming distance between &quot;toned&quot; and &quot;roses&quot; is 3.</span><br></pre></td></tr></table></figure>
<p><img data-src="/images/ml/02-knn-15.png" alt=""></p>
<p>汉明重量：是字符串相对于同样长度的零字符串的汉明距离，也就是说，它是字符串中非零的元素个数：对于二进制字符串来说，就是  <code>1</code>  的个数，所以  <code>11101</code>  的汉明重量是  <code>4</code> 。因此，如果向量空间中的元素 <code>a</code>  和 <code>b</code>  之间的汉明距离等于它们汉明重量的差 <code>a-b</code> 。</p>
<p>应用：汉明重量分析在包括信息论、编码理论、密码学等领域都有应用。比如在信息编码过程中，为了增强容错性，应使得编码间的最小汉明距离尽可能大。但是，如果要比较两个不同长度的字符串，不仅要进行替换，而且要进行插入与删除的运算，在这种场合下，通常使用更加复杂的编辑距离等算法。</p>
<h3 id="杰卡德距离jaccard-distance"><a class="markdownIt-Anchor" href="#杰卡德距离jaccard-distance">#</a> 杰卡德距离 (Jaccard Distance)</h3>
<p>杰卡德相似系数 ( <code>Jaccard similarity coefficient</code> )：两个集合 <code>A</code>  和 <code>B</code>  的交集元素在 <code>A</code> ， <code>B</code>  的并集中所占的比例，称为两个集合的杰卡德相似系数，用符号 <code>J(A,B</code> ) 表示：</p>
<p><img data-src="/images/ml/02-knn-16.png" alt=""></p>
<p>杰卡德距离 ( <code>Jaccard Distance</code> )：与杰卡德相似系数相反，用两个集合中不同元素占所有元素的比例来衡量两个集合的区分度：</p>
<p><img data-src="/images/ml/02-knn-17.png" alt=""></p>
<h3 id="马氏距离mahalanobis-distance"><a class="markdownIt-Anchor" href="#马氏距离mahalanobis-distance">#</a> 马氏距离 (Mahalanobis Distance)</h3>
<p>下图有两个正态分布图，它们的均值分别为 <code>a</code>  和 <code>b</code> ，但方差不一样，则图中的 <code>A</code>  点离哪个总体更近？或者说 <code>A</code>  有更大的概率属于谁？显然， <code>A</code>  离左边的更近， <code>A</code>  属于左边总体的概率更大，尽管 <code>A</code>  与 <code>a</code>  的欧式距离远一些。这就是马氏距离的直观解释。</p>
<p><img data-src="/images/ml/02-knn-18.png" alt=""></p>
<p>马氏距离是基于样本分布的一种距离。</p>
<p>马氏距离是由印度统计学家马哈拉诺比斯提出的，表示数据的协方差距离。它是一种有效的计算两个位置样本集的相似度的方法。</p>
<p>与欧式距离不同的是，它考虑到各种特性之间的联系，即独立于测量尺度。</p>
<p>马氏距离定义：设总体 <code>G</code>  为 <code>m</code>  维总体（考察 <code>m</code>  个指标），均值向量为 <code>μ=（μ1，μ2，… ...，μm，）</code> , 协方差阵为 <code>∑=（σij）</code> ,</p>
<p>则样本 <code>X=（X1，X2，… …，Xm，）</code> 与总体 G 的马氏距离定义为：</p>
<p><img data-src="/images/ml/02-knn-19.png" alt=""></p>
<p>马氏距离也可以定义为两个服从同一分布并且其协方差矩阵为 <code>∑</code> 的随机变量的差异程度：如果协方差矩阵为单位矩阵，马氏距离就简化为欧式距离；如果协方差矩阵为对角矩阵，则其也可称为正规化的欧式距离。</p>
<h4 id="马氏距离特性"><a class="markdownIt-Anchor" href="#马氏距离特性">#</a> 马氏距离特性：</h4>
<p>1. 量纲无关，排除变量之间的相关性的干扰；</p>
<p>2. 马氏距离的计算是建立在总体样本的基础上的，如果拿同样的两个样本，放入两个不同的总体中，最后计算得出的两个样本间的马氏距离通常是不相同的，除非这两个总体的协方差矩阵碰巧相同；</p>
<p>3 . 计算马氏距离过程中，要求总体样本数大于样本的维数，否则得到的总体样本协方差矩阵逆矩阵不存在，这种情况下，用欧式距离计算即可。</p>
<p>4. 还有一种情况，满足了条件总体样本数大于样本的维数，但是协方差矩阵的逆矩阵仍然不存在，比如三个样本点 <code>(3,4)</code> ， <code>(5,6)</code> ， <code>(7,8)</code> ，这种情况是因为这三个样本在其所处的二维空间平面内共线。这种情况下，也采用欧式距离计算。</p>
<h4 id="欧式距离马氏距离"><a class="markdownIt-Anchor" href="#欧式距离马氏距离">#</a> 欧式距离 &amp; 马氏距离：</h4>
<p><img data-src="/images/ml/02-knn-20.png" alt=""></p>
<p>举例：</p>
<p>已知有两个类 <code>G1</code>  和 <code>G2</code> ，比如 <code>G1</code>  是设备 <code>A</code>  生产的产品， <code>G2</code>  是设备 <code>B</code>  生产的同类产品。设备 <code>A</code>  的产品质量高（如考察指标为耐磨度 <code>X</code> ），其平均耐磨度 <code>μ1=80</code> ，反映设备精度的方差 <code>σ2(1)=0.25</code> ; 设备 B 的产品质量稍差，其平均耐磨损度 <code>μ2=75</code> ，反映设备精度的方差 <code>σ2(2)=4</code> .</p>
<p>今有一产品 <code>G0</code> ，测的耐磨损度 <code>X0=78</code> ，试判断该产品是哪一台设备生产的？</p>
<p>直观地看， <code>X0</code>  与 <code>μ1</code> （ <code>设备A</code> ）的绝对距离近些，按距离最近的原则，是否应把该产品判断 <code>设备A</code>  生产的？</p>
<p>考虑一种相对于分散性的距离，记 <code>X0</code>  与 <code>G1</code> ， <code>G2</code>  的相对距离为 <code>d1</code> ， <code>d2</code> , 则：</p>
<p><img data-src="/images/ml/02-knn-21.png" alt=""></p>
<p>因为 <code>d2=1.5 &lt; d1=4</code> ，按这种距离准则，应判断 <code>X0</code>  为设备 B 生产的。</p>
<p>设备 <code>B</code>  生产的产品质量较分散，出现 <code>X0</code>  为 <code>78</code>  的可能性较大；而 <code>设备A</code>  生产的产品质量较集中，出现 <code>X0</code>  为 <code>78</code>  的可能性较小。</p>
<p>这种相对于分散性的距离判断就是马氏距离。</p>
<p><img data-src="/images/ml/02-knn-22.png" alt=""></p>
<h2 id="案例"><a class="markdownIt-Anchor" href="#案例">#</a> 案例</h2>
<h3 id="预测鸢尾花种类"><a class="markdownIt-Anchor" href="#预测鸢尾花种类">#</a> 预测鸢尾花种类</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">iris_demo</span>():</span></span><br><span class="line">    <span class="comment"># 1.准备数据</span></span><br><span class="line">    iris = load_iris()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 2.数据基本处理</span></span><br><span class="line">    x_train, x_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=<span class="number">0.2</span>, random_state=<span class="number">22</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 3.特征工程</span></span><br><span class="line">    <span class="comment"># 3.1 标准化</span></span><br><span class="line">    transfer = StandardScaler()</span><br><span class="line">    x_train = transfer.fit_transform(x_train)</span><br><span class="line">    x_test = transfer.transform(x_test)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 4.机器训练(模型训练)</span></span><br><span class="line">    estimator = KNeighborsClassifier(n_neighbors=<span class="number">3</span>)</span><br><span class="line">    estimator.fit(x_train, y_train)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 5.模型评估</span></span><br><span class="line">    <span class="comment"># 5.1  方法1：比对真实值和预测值</span></span><br><span class="line">    predict_data = estimator.predict(x_test)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;预测值为: \n&quot;</span>, predict_data)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;比对真实值和预测值;\n&quot;</span>, predict_data == y_test)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 5.2  方法2: 直接计算正确率</span></span><br><span class="line">    score = estimator.score(x_test, y_test)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;正确率:&quot;</span>, score)</span><br></pre></td></tr></table></figure>
<h4 id="输出结果"><a class="markdownIt-Anchor" href="#输出结果">#</a> 输出结果</h4>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">预测值为: </span><br><span class="line"> [0 2 1 2 1 1 1 2 1 0 2 1 2 2 0 2 1 1 1 1 0 2 0 1 2 0 2 2 2 2]</span><br><span class="line">比对真实值和预测值;</span><br><span class="line"> [ True  True  True  True  True  True  True  True  True  True  True  True</span><br><span class="line">  True  True  True  True  True  True False  True  True  True  True  True</span><br><span class="line">  True  True  True  True  True  True]</span><br><span class="line">正确率: 0.9666666666666667</span><br></pre></td></tr></table></figure>
<h4 id="使用-gscv-优化"><a class="markdownIt-Anchor" href="#使用-gscv-优化">#</a> 使用 GSCV 优化</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split, GridSearchCV</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">iris_demo</span>():</span></span><br><span class="line">    <span class="comment"># 1.准备数据</span></span><br><span class="line">    iris = load_iris()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 2.数据基本处理</span></span><br><span class="line">    x_train, x_test, y_train, y_test = train_test_split(iris.data, iris.target, random_state=<span class="number">22</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 3.特征工程</span></span><br><span class="line">    <span class="comment"># 3.1 标准化</span></span><br><span class="line">    transfer = StandardScaler()</span><br><span class="line">    x_train = transfer.fit_transform(x_train)</span><br><span class="line">    x_test = transfer.transform(x_test)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 4.机器训练(模型训练)</span></span><br><span class="line">    estimator = KNeighborsClassifier()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 4.1 准备要调的超参数</span></span><br><span class="line">    param_dict = &#123;<span class="string">&quot;n_neighbors&quot;</span>: [<span class="number">1</span>, <span class="number">3</span>, <span class="number">5</span>]&#125;</span><br><span class="line">    <span class="comment"># 4.2 创建 GridSearchCV,使用网格搜索和交叉验证</span></span><br><span class="line">    estimator = GridSearchCV(estimator, param_grid=param_dict, cv=<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">    estimator.fit(x_train, y_train)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 5.模型评估</span></span><br><span class="line">    <span class="comment"># 5.1  方法1：比对真实值和预测值</span></span><br><span class="line">    predict_data = estimator.predict(x_test)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;预测值为: \n&quot;</span>, predict_data)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;比对真实值和预测值;\n&quot;</span>, predict_data == y_test)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 5.2  方法2: 直接计算正确率</span></span><br><span class="line">    score = estimator.score(x_test, y_test)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;正确率:&quot;</span>, score)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 6. 直接查看评估结果哦</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;在交叉验证中验证的最好结果：&quot;</span>, estimator.best_score_)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;最好的参数模型：&quot;</span>, estimator.best_estimator_)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;每次交叉验证后的准确率结果：\n&quot;</span>, estimator.cv_results_)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    iris_demo()</span><br></pre></td></tr></table></figure>
<h4 id="输出结果-2"><a class="markdownIt-Anchor" href="#输出结果-2">#</a> 输出结果</h4>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">预测值为: </span><br><span class="line"> [0 2 1 2 1 1 1 1 1 0 2 1 2 2 0 2 1 1 1 1 0 2 0 1 2 0 2 2 2 2 0 0 1 1 1 0 0</span><br><span class="line"> 0]</span><br><span class="line">比对真实值和预测值;</span><br><span class="line"> [ True  True  True  True  True  True  True False  True  True  True  True</span><br><span class="line">  True  True  True  True  True  True False  True  True  True  True  True</span><br><span class="line">  True  True  True  True  True  True  True  True  True  True  True  True</span><br><span class="line">  True  True]</span><br><span class="line">正确率: 0.9473684210526315</span><br><span class="line">在交叉验证中验证的最好结果： 0.9732100521574205</span><br><span class="line">最好的参数模型： KNeighborsClassifier()</span><br><span class="line">每次交叉验证后的准确率结果：</span><br><span class="line"> &#123;&#x27;mean_fit_time&#x27;: array([0.0008928 , 0.00045244, 0.00044529]), &#x27;std_fit_time&#x27;: array([5.74547103e-04, 5.05512361e-06, 2.92218150e-06]), &#x27;mean_score_time&#x27;: array([0.00226967, 0.00184425, 0.00182239]), &#x27;std_score_time&#x27;: array([6.28895378e-04, 2.09757168e-05, 1.41269575e-05]), &#x27;param_n_neighbors&#x27;: masked_array(data=[1, 3, 5],</span><br><span class="line">             mask=[False, False, False],</span><br><span class="line">       fill_value=&#x27;?&#x27;,</span><br><span class="line">            dtype=object), &#x27;params&#x27;: [&#123;&#x27;n_neighbors&#x27;: 1&#125;, &#123;&#x27;n_neighbors&#x27;: 3&#125;, &#123;&#x27;n_neighbors&#x27;: 5&#125;], &#x27;split0_test_score&#x27;: array([0.97368421, 0.97368421, 0.97368421]), &#x27;split1_test_score&#x27;: array([0.97297297, 0.97297297, 0.97297297]), &#x27;split2_test_score&#x27;: array([0.94594595, 0.89189189, 0.97297297]), &#x27;mean_test_score&#x27;: array([0.96420104, 0.94618303, 0.97321005]), &#x27;std_test_score&#x27;: array([0.01291157, 0.03839073, 0.00033528]), &#x27;rank_test_score&#x27;: array([2, 3, 1], dtype=int32)&#125;</span><br></pre></td></tr></table></figure>
<h3 id="预测facebook签到位置"><a class="markdownIt-Anchor" href="#预测facebook签到位置">#</a> 预测 facebook 签到位置</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">facebook_demo</span>():</span></span><br><span class="line">    <span class="comment"># 准备数据</span></span><br><span class="line">    data = pd.read_csv(<span class="string">&#x27;./train.csv&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(data.head())</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 2.数据基本处理</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">## 2.1 处理时间特征</span></span><br><span class="line">    time = pd.to_datetime(data[<span class="string">&#x27;time&#x27;</span>], unit=<span class="string">&#x27;s&#x27;</span>)</span><br><span class="line">    time = pd.DatetimeIndex(time)</span><br><span class="line"></span><br><span class="line">    data[<span class="string">&#x27;hour&#x27;</span>] = time.hour</span><br><span class="line">    data[<span class="string">&#x27;day&#x27;</span>] = time.day</span><br><span class="line">    data[<span class="string">&#x27;weekday&#x27;</span>] = time.weekday</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(data.head(<span class="number">10</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 2.2.去掉签到少的地方</span></span><br><span class="line">    place_count = data.groupby(<span class="string">&quot;place_id&quot;</span>).count()</span><br><span class="line">    place_count = place_count[place_count[<span class="string">&quot;row_id&quot;</span>] &gt; <span class="number">3</span>]</span><br><span class="line">    data = data[data[<span class="string">&quot;place_id&quot;</span>].isin(place_count.index)]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 2.3 确定特征和目标值</span></span><br><span class="line">    x = data[[<span class="string">&#x27;x&#x27;</span>, <span class="string">&#x27;y&#x27;</span>, <span class="string">&quot;accuracy&quot;</span>, <span class="string">&quot;day&quot;</span>, <span class="string">&quot;hour&quot;</span>, <span class="string">&quot;weekday&quot;</span>]]</span><br><span class="line">    y = data[[<span class="string">&#x27;place_id&#x27;</span>]]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 2.4 拆分数据集</span></span><br><span class="line">    x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=<span class="number">22</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 3. 特征处理</span></span><br><span class="line">    <span class="comment"># 3.1 标准化处理</span></span><br><span class="line">    transfer = StandardScaler()</span><br><span class="line">    x_train = transfer.fit_transform(x_train)</span><br><span class="line">    x_test = transfer.transform(x_test)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 4.机器学习</span></span><br><span class="line">    <span class="comment"># 4.1 实例化估计器</span></span><br><span class="line">    estimator = KNeighborsClassifier()</span><br><span class="line">    param_dict = &#123;<span class="string">&#x27;neighbors&#x27;</span>: [<span class="number">1</span>, <span class="number">3</span>, <span class="number">5</span>]&#125;</span><br><span class="line">    estimator = GridSearchCV(estimator=estimator, param_grid=param_dict)</span><br><span class="line">    <span class="comment"># 4.2 模型训练</span></span><br><span class="line">    estimator.fit(x_train, y_train)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 模型评估</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\n最后预测的准确率为: &quot;</span>, estimator.score(x_test, y_test))</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\n在交叉验证中验证的最好结果:\n&quot;</span>, estimator.best_score_)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\n最好的参数模型:\n&quot;</span>, estimator.best_estimator_)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\n每次交叉验证后的验证集准确率结果和训练集准确率结果:\n&quot;</span>, estimator.cv_results_)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    facebook_demo()</span><br></pre></td></tr></table></figure>
<p>本案例来自  <code>Kaggle</code>  的题目，感兴趣的朋友可以登录:<span class="exturl" data-url="aHR0cHM6Ly93d3cua2FnZ2xlLmNvbS9uYXZvc2h0YS9ncmlkLWtubi9zY3JpcHQ=">https://www.kaggle.com/navoshta/grid-knn/script</span>  查看</p>
<h2 id="最后"><a class="markdownIt-Anchor" href="#最后">#</a> 最后</h2>
<p>希望和你一起遇见更好的自己</p>
<p><img data-src="/images/ml/qrcode.jpg" alt="qrcode"></p>

      <div class="asb asb-post-01" style="display:none;">
        <div class="mask"></div>
        <div class="info">
          <div>
              扫码或搜索：<span style="color: #E9405A; font-weight: bold;">方家小白</span>
          </div>
          <div>
              <span>发送 </span><span id="readmore_uniq_code" class="token" style="color: #e9415a; font-weight: bold; font-size: 17px; margin-bottom: 45px;">290992</span>
          </div>
          <div>
              即可<span style="color: #e9415a; font-weight: bold;">立即永久</span>解锁本站全部文章
          </div>
          <div>
            <img class="code-img" style="width: 300px;display:unset" src="https://fangjiaxiaobai.github.io/images/qrcode.jpg">
          </div>
      </div>
    </div>
      <div class="tags">
          <a href="/tags/MachineLearn/" rel="tag"><i class="ic i-tag"></i> MachineLearn</a>
          <a href="/tags/KNN/" rel="tag"><i class="ic i-tag"></i> KNN</a>
      </div>
  </div>

   <footer>

    <div class="meta">
  <span class="item">
    <span class="icon">
      <i class="ic i-calendar-check"></i>
    </span>
    <span class="text">更新于</span>
    <time title="修改时间：2021-11-11 21:42:06" itemprop="dateModified" datetime="2021-11-11T21:42:06+08:00">2021-11-11</time>
  </span>
  <span id="2021/10/29/machine-learn/机器学习02-K-近邻算法/" class="item leancloud_visitors" data-flag-title="K - 近邻算法 (KNN)" title="阅读次数">
      <span class="icon">
        <i class="ic i-eye"></i>
      </span>
      <span class="text">阅读次数</span>
      <span class="leancloud-visitors-count"></span>
      <span class="text">次</span>
  </span>
</div>

      
<div class="reward">
  <button><i class="ic i-heartbeat"></i> 支持一下</button>
  <p>请我喝[咖啡]~(￣▽￣)~*</p>
  <div id="qr">
      
      <div>
        <img data-src="/images/wechatpay.png" alt="方小白 微信支付">
        <p>微信支付</p>
      </div>
      
      <div>
        <img data-src="/images/alipay.png" alt="方小白 支付宝">
        <p>支付宝</p>
      </div>
      <div>
        <img data-src="/images/numberpay.jpg" alt="方小白 numberpay">
        <p>numberpay</p>
      </div>
  </div>
</div>

      

<div id="copyright">
<ul>
  <li class="author">
    <strong>本文作者： </strong>方小白 <i class="ic i-at"><em>@</em></i>方家小白
  </li>
  <li class="link">
    <strong>本文链接：</strong>
    <a href="https://fangjiaxiaobai.github.io/2021/10/29/machine-learn/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A002-K-%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%95/" title="K - 近邻算法 (KNN)">https://fangjiaxiaobai.github.io/2021/10/29/machine-learn/机器学习02-K-近邻算法/</a>
  </li>
  <li class="license">
    <strong>版权声明： </strong>本站所有文章除特别声明外，均采用 <span class="exturl" data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC9kZWVkLnpo"><i class="ic i-creative-commons"><em>(CC)</em></i>BY-NC-SA</span> 许可协议。转载请注明出处！
  </li>
</ul>
</div>

  </footer>

</article>

  </div>
  

<div class="post-nav">
    <div class="item left">
      

  <a href="/2021/10/28/machine-learn/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A001-%E7%AE%80%E5%8D%95%E4%BB%8B%E7%BB%8D%E5%92%8C%E4%BA%86%E8%A7%A3/" itemprop="url" rel="prev" data-background-image="https:&#x2F;&#x2F;fangjiaxiaobai.github.io&#x2F;images&#x2F;ml&#x2F;covers&#x2F;14.png" title="机器学习-简介">
  <span class="type">上一篇</span>
  <span class="category"><i class="ic i-flag"></i> MachineLearn</span>
  <h3>机器学习-简介</h3>
  </a>

    </div>
    <div class="item right">
      

  <a href="/2021/11/01/BQ/LeetCode/0575-distribute-candies/" itemprop="url" rel="next" data-background-image="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;mw690&#x2F;6833939bly1giclfb3vzhj20zk0m8wny.jpg" title="LC:575.分糖果">
  <span class="type">下一篇</span>
  <span class="category"><i class="ic i-flag"></i> LeetCode 系列</span>
  <h3>LC:575.分糖果</h3>
  </a>

    </div>
</div>

  
  <div class="wrap" id="comments"></div>


        </div>
        <div id="sidebar">
          

<div class="inner">

  <div class="panels">
    <div class="inner">
      <div class="contents panel pjax" data-title="文章目录">
          <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%9A%E4%B9%89"><span class="toc-number">1.</span> <span class="toc-text"> 定义</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AE%97%E6%B3%95%E7%9A%84%E7%90%86%E8%A7%A3"><span class="toc-number">2.</span> <span class="toc-text"> 算法的理解</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#k%E5%80%BC%E7%9A%84%E9%80%89%E6%8B%A9"><span class="toc-number">3.</span> <span class="toc-text"> k 值的选择</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#knn%E7%9A%84%E4%BC%98%E5%8C%96"><span class="toc-number">4.</span> <span class="toc-text"> KNN 的优化</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%B7%9D%E7%A6%BB%E7%9A%84%E8%AE%A1%E7%AE%97"><span class="toc-number">5.</span> <span class="toc-text"> 距离的计算</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9B%BC%E5%93%88%E9%A1%BF%E8%B7%9D%E7%A6%BB"><span class="toc-number">5.1.</span> <span class="toc-text"> 曼哈顿距离</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%87%E6%AF%94%E9%9B%AA%E5%A4%AB%E8%B7%9D%E7%A6%BB-chebyshev-distance"><span class="toc-number">5.2.</span> <span class="toc-text"> 切比雪夫距离 (Chebyshev Distance)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%97%B5%E5%8F%AF%E5%A4%AB%E6%96%AF%E5%9F%BA%E8%B7%9D%E7%A6%BBminkowski-distance"><span class="toc-number">5.3.</span> <span class="toc-text"> 闵可夫斯基距离 (Minkowski Distance)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A0%87%E5%87%86%E5%8C%96%E6%AC%A7%E6%B0%8F%E8%B7%9D%E7%A6%BB-standardized-euclideandistance"><span class="toc-number">5.4.</span> <span class="toc-text"> 标准化欧氏距离 (Standardized EuclideanDistance)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BD%99%E5%BC%A6%E8%B7%9D%E7%A6%BBcosine-distance"><span class="toc-number">5.5.</span> <span class="toc-text"> 余弦距离 (Cosine Distance)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B1%89%E6%98%8E%E8%B7%9D%E7%A6%BBhamming-distance"><span class="toc-number">5.6.</span> <span class="toc-text"> 汉明距离 (Hamming Distance)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9D%B0%E5%8D%A1%E5%BE%B7%E8%B7%9D%E7%A6%BBjaccard-distance"><span class="toc-number">5.7.</span> <span class="toc-text"> 杰卡德距离 (Jaccard Distance)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%A9%AC%E6%B0%8F%E8%B7%9D%E7%A6%BBmahalanobis-distance"><span class="toc-number">5.8.</span> <span class="toc-text"> 马氏距离 (Mahalanobis Distance)</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%A9%AC%E6%B0%8F%E8%B7%9D%E7%A6%BB%E7%89%B9%E6%80%A7"><span class="toc-number">5.8.1.</span> <span class="toc-text"> 马氏距离特性：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%AC%A7%E5%BC%8F%E8%B7%9D%E7%A6%BB%E9%A9%AC%E6%B0%8F%E8%B7%9D%E7%A6%BB"><span class="toc-number">5.8.2.</span> <span class="toc-text"> 欧式距离 &amp; 马氏距离：</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A1%88%E4%BE%8B"><span class="toc-number">6.</span> <span class="toc-text"> 案例</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%A2%84%E6%B5%8B%E9%B8%A2%E5%B0%BE%E8%8A%B1%E7%A7%8D%E7%B1%BB"><span class="toc-number">6.1.</span> <span class="toc-text"> 预测鸢尾花种类</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%BE%93%E5%87%BA%E7%BB%93%E6%9E%9C"><span class="toc-number">6.1.1.</span> <span class="toc-text"> 输出结果</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8-gscv-%E4%BC%98%E5%8C%96"><span class="toc-number">6.1.2.</span> <span class="toc-text"> 使用 GSCV 优化</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%BE%93%E5%87%BA%E7%BB%93%E6%9E%9C-2"><span class="toc-number">6.1.3.</span> <span class="toc-text"> 输出结果</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%A2%84%E6%B5%8Bfacebook%E7%AD%BE%E5%88%B0%E4%BD%8D%E7%BD%AE"><span class="toc-number">6.2.</span> <span class="toc-text"> 预测 facebook 签到位置</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9C%80%E5%90%8E"><span class="toc-number">7.</span> <span class="toc-text"> 最后</span></a></li></ol>
      </div>
      <div class="related panel pjax" data-title="系列文章">
        <ul>
          <li><a href="/2021/10/28/machine-learn/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A001-%E7%AE%80%E5%8D%95%E4%BB%8B%E7%BB%8D%E5%92%8C%E4%BA%86%E8%A7%A3/" rel="bookmark" title="机器学习-简介">机器学习-简介</a></li><li class="active"><a href="/2021/10/29/machine-learn/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A002-K-%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%95/" rel="bookmark" title="K-近邻算法(KNN)">K-近邻算法(KNN)</a></li><li><a href="/2021/11/17/machine-learn/Model-evaluation/01-overview/" rel="bookmark" title="模型评估概述">模型评估概述</a></li><li><a href="/2021/11/17/machine-learn/Model-evaluation/02-confusion_matrix/" rel="bookmark" title="模型评估之 分类模型的评估指标">模型评估之 分类模型的评估指标</a></li>
        </ul>
      </div>
      <div class="overview panel" data-title="站点概览">
        <div class="author" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <img class="image" itemprop="image" alt="方小白"
      data-src="/images/avatar.jpg">
  <p class="name" itemprop="name">方小白</p>
  <div class="description" itemprop="description">和你一起遇见更好的自己</div>
</div>

<nav class="state">
    <div class="item posts">
      <a href="/archives/">
        <span class="count">107</span>
        <span class="name">文章</span>
      </a>
    </div>
    <div class="item categories">
      <a href="/categories/">
        <span class="count">23</span>
        <span class="name">分类</span>
      </a>
    </div>
    <div class="item tags">
      <a href="/tags/">
        <span class="count">66</span>
        <span class="name">标签</span>
      </a>
    </div>
</nav>

<div class="social">
      <span class="exturl item github" data-url="aHR0cHM6Ly9naXRodWIuY29tL2ZhbmdqaWF4aWFvYmFp" title="https:&#x2F;&#x2F;github.com&#x2F;fangjiaxiaobai"><i class="ic i-github"></i></span>
      <span class="exturl item twitter" data-url="aHR0cHM6Ly90d2l0dGVyLmNvbS9mYW5namlheGlhb2JhaQ==" title="https:&#x2F;&#x2F;twitter.com&#x2F;fangjiaxiaobai"><i class="ic i-twitter"></i></span>
      <span class="exturl item zhihu" data-url="aHR0cHM6Ly93d3cuemhpaHUuY29tL3Blb3BsZS9mYW5namlheGlhb2JhaQ==" title="https:&#x2F;&#x2F;www.zhihu.com&#x2F;people&#x2F;fangjiaxiaobai"><i class="ic i-zhihu"></i></span>
      <span class="exturl item music" data-url="aHR0cHM6Ly9tdXNpYy4xNjMuY29tLyMvdXNlci9ob21lP2lkPTc3NDY2OTM3" title="https:&#x2F;&#x2F;music.163.com&#x2F;#&#x2F;user&#x2F;home?id&#x3D;77466937"><i class="ic i-cloud-music"></i></span>
      <span class="exturl item email" data-url="bWFpbHRvOmZhbmdqaWF4aWFvYmFpQDE2My5jb20=" title="mailto:fangjiaxiaobai@163.com"><i class="ic i-envelope"></i></span>
</div>

<ul class="menu">
  
    
  <li class="item">
    <a href="/" rel="section"><i class="ic i-home"></i>首页</a>
  </li>

        
  <li class="item dropdown">
      <a href="javascript:void(0);"><i class="ic i-feather"></i>文章</a>
    <ul class="submenu">

        
  <li class="item">
    <a href="/archives/" rel="section"><i class="ic i-list-alt"></i>归档</a>
  </li>

        
  <li class="item">
    <a href="/categories/" rel="section"><i class="ic i-th"></i>分类</a>
  </li>

        
  <li class="item">
    <a href="/tags/" rel="section"><i class="ic i-tags"></i>标签</a>
  </li>

  </ul>
        
  <li class="item dropdown">
      <a href="javascript:void(0);"><i class="ic i-magic"></i>系列</a>
    <ul class="submenu">

        
  <li class="item">
    <a href="/series/leetcode" rel="section"><i class="ic i-music"></i>LeetCode系列</a>
  </li>

        
  <li class="item">
    <a href="/series/MySQL" rel="section"><i class="ic i-sakura"></i>MySQL系列</a>
  </li>

        
  <li class="item">
    <a href="/series/Redis" rel="section"><i class="ic i-snapchat-ghost"></i>Redis系列</a>
  </li>

        
  <li class="item">
    <a href="/series/Netty" rel="section"><i class="ic i-clipboard"></i>Netty系列</a>
  </li>

        
  <li class="item">
    <a href="/series/java" rel="section"><i class="ic i-coffee"></i>Java系列</a>
  </li>

        
  <li class="item">
    <a href="/series/git" rel="section"><i class="ic i-link-alt"></i>Git系列</a>
  </li>

  </ul>
    
  <li class="item">
    <a href="/links" rel="section"><i class="ic i-magic"></i>链接</a>
  </li>

        
  <li class="item dropdown">
      <a href="javascript:void(0);"><i class="ic i-chart-area"></i>推广</a>
    <ul class="submenu">

        
  <li class="item">
    <a href="/promotions/geekbang" rel="section"><i class="ic i-envelope"></i>极客时间</a>
  </li>

        
  <li class="item">
    <a href="/promotions/vpn" rel="section"><i class="ic i-thumbtack"></i>科学上网</a>
  </li>

        
  <li class="item">
    <a href="/promotions/common" rel="section"><i class="ic i-times"></i>书籍资料</a>
  </li>

  </ul>
        
  <li class="item dropdown">
      <a href="javascript:void(0);"><i class="ic i-user"></i>关于</a>
    <ul class="submenu">

        
  <li class="item">
    <a href="/about/me" rel="section"><i class="ic i-user"></i>关于我</a>
  </li>

        
  <li class="item">
    <a href="/about/love" rel="section"><i class="ic i-heart"></i>关于她</a>
  </li>

  </ul>

</ul>

      </div>
    </div>
  </div>

  <ul id="quick">
    <li class="prev pjax">
        <a href="/2021/10/28/machine-learn/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A001-%E7%AE%80%E5%8D%95%E4%BB%8B%E7%BB%8D%E5%92%8C%E4%BA%86%E8%A7%A3/" rel="prev" title="上一篇"><i class="ic i-chevron-left"></i></a>
    </li>
    <li class="up"><i class="ic i-arrow-up"></i></li>
    <li class="down"><i class="ic i-arrow-down"></i></li>
    <li class="next pjax">
        <a href="/2021/11/01/BQ/LeetCode/0575-distribute-candies/" rel="next" title="下一篇"><i class="ic i-chevron-right"></i></a>
    </li>
    <li class="percent"></li>
  </ul>
</div>


        </div>
        <div class="dimmer"></div>
      </div>
    </main>
    <footer id="footer">
      <div class="inner">
        <div class="widgets">
          
<div class="rpost pjax">
  <h2>随机文章</h2>
  <ul>
      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/%E5%85%A8%E7%AB%99%E5%9C%B0%E5%9B%BE/" title="分类于 全站地图">全站地图</a>
</div>

    <span><a href="/2021/07/18/RoadMap/" title="全站地图">全站地图</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/RocketMQ%E7%B3%BB%E5%88%97/" title="分类于 RocketMQ 系列">RocketMQ 系列</a>
</div>

    <span><a href="/2021/09/01/rocketMQ/README/" title="RocketMQ系列-开篇">RocketMQ系列-开篇</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/MySQL%E6%95%B0%E6%8D%AE%E5%BA%93/" title="分类于 MySQL 数据库">MySQL 数据库</a>
</div>

    <span><a href="/2021/07/24/MySQL%E7%B3%BB%E5%88%97/%E6%95%B0%E6%8D%AE%E5%BA%931-01.%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E7%89%88%E6%9C%AC/" title="MySQL数据库的版本">MySQL数据库的版本</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/RocketMQ%E7%B3%BB%E5%88%97/" title="分类于 RocketMQ 系列">RocketMQ 系列</a>
</div>

    <span><a href="/2021/09/04/rocketMQ/1-04-00.RocketMQ%E5%B8%B8%E8%A7%81%E6%A1%88%E4%BE%8B/" title="RocketMQ系列-在Java应用中的使用">RocketMQ系列-在Java应用中的使用</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/k8s/" title="分类于 k8s">k8s</a>
</div>

    <span><a href="/2022/07/17/k8s/seris02-how-to-build/" title="k8s-搭建K8s集群">k8s-搭建K8s集群</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/Redis%E6%95%B0%E6%8D%AE%E5%BA%93/" title="分类于 Redis 数据库">Redis 数据库</a>
</div>

    <span><a href="/2021/08/01/Redis%E7%B3%BB%E5%88%97/02-Redis%E7%9A%84%E5%A4%9A%E4%B8%AA%E6%95%B0%E6%8D%AE%E5%BA%93/" title="Redis 多个数据库">Redis 多个数据库</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/LeetCode%E7%B3%BB%E5%88%97/" title="分类于 LeetCode 系列">LeetCode 系列</a>
</div>

    <span><a href="/2021/08/19/BQ/LeetCode/0001-%E5%8F%8D%E8%BD%AC%E6%95%B0%E7%BB%84/" title="LC:反转数组">LC:反转数组</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/%E6%9D%AD%E7%94%B5Oj/" title="分类于 杭电 Oj">杭电 Oj</a>
</div>

    <span><a href="/2021/10/16/BQ/hdoj/HD-1003/" title="1003 Max Sum">1003 Max Sum</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/Redis%E6%95%B0%E6%8D%AE%E5%BA%93/" title="分类于 Redis 数据库">Redis 数据库</a>
</div>

    <span><a href="/2021/08/01/Redis%E7%B3%BB%E5%88%97/B-4-Redis%E7%9A%84%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E4%B9%8B%E9%9B%86%E5%90%88set/" title="Redis数据结构之集合 Set">Redis数据结构之集合 Set</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/" title="分类于 数据结构与算法">数据结构与算法</a>
</div>

    <span><a href="/2021/09/01/dataStructuresAndAlgorithms/sort/%E7%AE%97%E6%B3%9503-%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F/" title="快速排序">快速排序</a></span>
  </li>

  </ul>
</div>
<div>
  <h2>最新评论</h2>
  <ul class="leancloud-recent-comment"></ul>
</div>

        </div>
        <div class="status">
  <div class="copyright">
    
    &copy; 2021 – 
    <span itemprop="copyrightYear">2022</span>
    <span class="with-love">
      <i class="ic i-sakura rotate"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">方小白 @ 方家小白</span>
  </div>
  <div class="count">
    <span class="post-meta-item-icon">
      <i class="ic i-chart-area"></i>
    </span>
    <span title="站点总字数">465k 字</span>

    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="ic i-coffee"></i>
    </span>
    <span title="站点阅读时长">7:03</span>
  </div>
  <div class="powered-by">
    基于 <span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlv">Hexo</span> & Theme.<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2FtZWhpbWUvaGV4by10aGVtZS1zaG9rYQ==">Shoka</span>
  </div>
</div>

      </div>
    </footer>
  </div>
<script data-config type="text/javascript">
  var LOCAL = {
    path: '2021/10/29/machine-learn/机器学习02-K-近邻算法/',
    favicon: {
      show: "方家小白",
      hide: "方家小白"
    },
    search : {
      placeholder: "文章搜索",
      empty: "关于 「 ${query} 」，什么也没搜到",
      stats: "${time} ms 内找到 ${hits} 条结果"
    },
    valine: true,fancybox: true,copyright: '复制成功，转载请遵守 <i class="ic i-creative-commons"></i>BY-NC-SA 协议。',
    ignores : [
      function(uri) {
        return uri.includes('#');
      },
      function(uri) {
        return new RegExp(LOCAL.path+"$").test(uri);
      }
    ]
  };
</script>

<script src="https://cdn.polyfill.io/v2/polyfill.js"></script>

<script src="//cdn.jsdelivr.net/combine/npm/pace-js@1.0.2/pace.min.js,npm/pjax@0.2.8/pjax.min.js,npm/whatwg-fetch@3.4.0/dist/fetch.umd.min.js,npm/animejs@3.2.0/lib/anime.min.js,npm/algoliasearch@4/dist/algoliasearch-lite.umd.js,npm/instantsearch.js@4/dist/instantsearch.production.min.js,npm/lozad@1/dist/lozad.min.js,npm/quicklink@2/dist/quicklink.umd.js"></script>

<script src="/js/app.js?v=0.2.5"></script>




</body>
</html>
