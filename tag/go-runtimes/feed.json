{
    "version": "https://jsonfeed.org/version/1",
    "title": "方家小白 • All posts by \"go-runtimes\" tag",
    "description": "和你一起遇见更好的自己",
    "home_page_url": "https://fangjiaxiaobai.github.io",
    "items": [
        {
            "id": "https://fangjiaxiaobai.github.io/2022/03/12/go/goroutine_runtime/",
            "url": "https://fangjiaxiaobai.github.io/2022/03/12/go/goroutine_runtime/",
            "title": "Go 运行时",
            "date_published": "2022-03-12T10:18:18.000Z",
            "content_html": "<h2 id=\"goroutine-定义\"><a class=\"markdownIt-Anchor\" href=\"#goroutine-定义\">#</a>  <code>goroutine</code>  定义</h2>\n<p>“ <code>Goroutine</code>  是一个与其他  <code>goroutines</code>  并行运行在同一地址空间的  <code>Go</code>  函数或方法。一个运行的程序由一个或更多个  <code>goroutine</code>  组成。它与线程、协程、进程等不同。它是一个  <code>goroutine</code> ” ——  <code>Rob Pike</code> <br>\n <code>Goroutines</code>  在同一个用户地址空间里并行独立执行  <code>functions</code>  ，  <code>channels</code>  则用于  <code>goroutines</code>  间的通信和同步访问控制。</p>\n<h3 id=\"goroutine-vs-thread\"><a class=\"markdownIt-Anchor\" href=\"#goroutine-vs-thread\">#</a>  <code>goroutine VS thread</code></h3>\n<ul>\n<li><b>内存占用</b>. 创建一个  <code>goroutine</code>  的栈内存消耗为  <code>2 KB</code> ( <code>Linux AMD64</code>   <code>Go v1.4</code>  后)，运行过程中，如果栈空间不够用，会自动进行扩容。 创建一个  <code>thread</code>  为了尽量避免极端情况下操作系统线程栈的溢出，默认会为其分配一个较大的栈内存 (  <code>1 - 8 MB</code>  栈内存，线程标准 <code>POSIX Thread</code> )，而且还需要一个被称为  <code>“guard page”</code>  的区域用于和其他  <code>thread</code>  的栈空间进行隔离。而栈内存空间一旦创建和初始化完成之后其大小就不能再有变化，这决定了<b>在某些特殊场景下系统线程栈还是有溢出的风险</b>。</li>\n<li><b>创建 / 销毁</b>，线程创建和销毀都会有巨大的消耗，是内核级的交互 ( <code>trap</code> )。  <code>POSIX</code>  线程 (定义了创建和操纵线程的一套  <code>API</code> ) 通常是在已有的进程模型中增加的逻辑扩展，所以线程控制和进程控制很相似。而进入内核调度所消耗的性能代价比较高，开销较大。  <code>goroutine</code>  是用户态线程，是由  <code>go runtime</code>  管理，创建和销毁的消耗非常小。</li>\n<li><b>调度切换</b> 抛开陷入内核，线程切换会消耗  <code>1000-1500</code>  纳秒 (上下文保存成本高，较多寄存器，公平性，复杂时间计算统计)，一个纳秒平均可以执行  <code>12-18</code>  条指令。 所以由于线程切换，执行指令的条数会减少  <code>12000-18000</code> 。  <code>goroutine</code>  的切换约为  <code>200ns</code>  (用户态、3 个寄存器)，相当于  <code>2400-3600</code>  条指令。因此，  <code>goroutines</code>  切换成本比   <code>threads</code>  要小得多。</li>\n<li><b>复杂性</b> 线程的创建和退出复杂，多个  <code>thread</code>  间通讯复杂 ( <code>share memory</code> )。 不能大量创建线程 (参考早期的  <code>httpd</code> )，成本高，使用网络多路复用，存在大量 <code>callback</code>  (参考 <code>twemproxy</code> 、 <code>nginx</code>  的代码) 。对于应用服务线程门槛高，例如需要做第三方库隔离，需要考虑引入线程池等。</li>\n</ul>\n<h2 id=\"goroutine-运行原理\"><a class=\"markdownIt-Anchor\" href=\"#goroutine-运行原理\">#</a>  <code>Goroutine</code>  运行原理</h2>\n<p><code>Go</code>  程序的执行由两层组成： <code>Go Program</code> ， <code>Runtime</code> ，即用户程序和运行时。它们之间通过函数调用来实现内存管理、 <code>channel</code>  通信、 <code>goroutines</code>  创建等功能。用户程序进行的系统调用都会被  <code>Runtime</code>  拦截，以此来帮助它进行调度以及垃圾回收相关的工作。</p>\n<h3 id=\"mn-模型\"><a class=\"markdownIt-Anchor\" href=\"#mn-模型\">#</a>  <code>M:N</code>  模型</h3>\n<p><code>Go runtime</code>  会负责  <code>goroutine</code>  的生老病死，从创建到销毁，都一手包办。 <code>Runtime</code>  会在程序启动的时候。  <code>Go</code>  创建  <code>M</code>  个线程 ( <code>CPU</code>  执行调度的单元，内核的  <code>task_struct</code> )，之后创建的  <code>N</code>  个  <code>goroutine</code>  都会依附在这  <code>M</code>  个线程上执行，即  <code>M:N</code>  模型。它们能够同时运行，与线程类似，但相比之下非常轻量。因此，程序运行时， <code>Goroutines</code>  的个数应该是远大于线程的个数的（<a href=\"https://www.zhihu.com/question/35128513\"> <code>phread</code>  是内核线程？</a>）。</p>\n<p>同一个时刻，一个线程只能跑一个  <code>goroutine</code> 。当  <code>goroutine</code>  发生阻塞 ( <code>chan</code>  阻塞、 <code>mutex</code> 、 <code>syscall</code>  等等) 时，Go 会把当前的  <code>goroutine</code>  调度走，让其他  <code>goroutine</code>  来继续执行，而不是让线程阻塞休眠，尽可能多的分发任务出去，让  <code>CPU</code>  忙。</p>\n<h3 id=\"gm-调度模型\"><a class=\"markdownIt-Anchor\" href=\"#gm-调度模型\">#</a> GM 调度模型</h3>\n<p><code>go</code>  在 <code>1.2</code>  版本之前，调度模型使用的是  <code>GM</code>  调度模型。</p>\n<h4 id=\"g\"><a class=\"markdownIt-Anchor\" href=\"#g\">#</a> G</h4>\n<p><code>goroutine</code>  的缩写，每次  <code>go func()</code>  都代表一个  <code>G</code> ，无限制。 使用  <code>struct runtime.g</code> ，包含了当前  <code>goroutine</code>  的状态、堆栈、上下文。</p>\n<h4 id=\"m\"><a class=\"markdownIt-Anchor\" href=\"#m\">#</a> M</h4>\n<p>工作线程 ( <code>OS thread</code> ) 也被称为 Machine，使用  <code>struct runtime.m</code> ，所有  <code>M</code>  是有线程栈的。 如果不对该线程栈提供内存的话，系统会给该线程栈提供内存 (不同操作系统提供的线程栈大小不同)<br>\n。当指定了线程栈，则  <code>M.stack→G.stack</code> ， <code>M</code>  的  <code>PC</code>  寄存器指向  <code>G</code>  提供的函数，然后去执行。</p>\n<h4 id=\"gm-调度\"><a class=\"markdownIt-Anchor\" href=\"#gm-调度\">#</a> GM 调度</h4>\n<p><code>Go 1.2</code>  前的调度器实现，限制了  <code>Go</code>  并发程序的伸缩性，尤其是对那些有高吞吐或并行计算需求的服务程序。<br>\n每个  <code>goroutine</code>  对应于  <code>runtime</code>  中的一个抽象结构： <code>G</code> ，而  <code>thread</code>  作为 <code>“物理 CPU”</code>  的存在而被抽象为一个结构：M ( <code>machine</code> )。当  <code>goroutine</code>  调用了一个阻塞的系统调用，运行这个  <code>goroutine</code>  的线程就会被阻塞，这时至少应该再创建 / 唤醒一个线程来运行别的没有阻塞的  <code>goroutine</code>  。线程这里可以创建不止一个，可以按需不断地创建，而活跃的线程（处于非阻塞状态的线程）的最大个数存储在变量  <code>GOMAXPROCS</code>  中。</p>\n<p>调用过程如下所示:</p>\n<p><img data-src=\"/images/go/13-75.png\" alt=\"\"></p>\n<p><code>M</code>  想要执行、放回  <code>G</code>  都必须访问全局  <code>G</code>  队列，并且  <code>M</code>  有多个，即多线程访问同一资源需要加锁进行保证互斥 / 同步，所以全局  <code>G</code>  队列是有互斥锁进行保护的</p>\n<h4 id=\"gm-调度模型的问题\"><a class=\"markdownIt-Anchor\" href=\"#gm-调度模型的问题\">#</a> GM 调度模型的问题</h4>\n<ul>\n<li>单一全局互斥锁 ( <code>Sched.Lock</code> ) 和集中状态存储<br>\n导致所有  <code>goroutine</code>  相关操作，比如：创建、结束、重新调度等都要上锁。</li>\n<li><code>Goroutine</code>  传递问题<br>\n <code>M</code>  经常在  <code>M</code>  之间传递” 可运行” 的  <code>goroutine</code>  ，这导致调度延迟增大以及额外的性能损耗（刚创建的  <code>G</code>  放到了全局队列，而不是本地 M 执行，不必要的开销和延迟）。</li>\n<li><code>Per-M </code> 持有内存缓存 ( <code>M.mcache</code> )<br>\n 每个  <code>M</code>  持有  <code>mcache</code>  和  <code>stackalloc</code>  ，然而只有在  <code>M</code>  运行  <code>Go</code>  代码时才需要使用的内存 (每个  <code>mcache</code>  可以高达  <code>2mb</code>  )，当  <code>M</code>  在处于  <code>syscall</code>  时并不需要。运行  <code>Go</code>  代码和阻塞在  <code>syscall</code>  的  <code>M</code>  的比例高达 <code>1:100</code> ，造成了很大的浪费。同时内存亲缘性也较差， <code>G</code>  当前在  <code>M</code>  运行后对 M 的内存进行了预热，因为现在  <code>G</code>  调度到同一个  <code>M</code>  的概率不高，数据局部性不好。</li>\n<li>严重的线程阻塞 / 解锁<br>\n在系统调用的情况下，工作线程经常被阻塞和取消阻塞，这增加了很多开销。比如  <code>M</code>  找不到 <code>G</code> ，此时  <code>M</code>  就会进入频繁阻塞 / 唤醒来进行检查的逻辑，以便及时发现新的  <code>G</code>  来执行。<br>\nby Dmitry Vyukov “<span class=\"exturl\" data-url=\"aHR0cHM6Ly9kb2NzLmdvb2dsZS5jb20vZG9jdW1lbnQvZC8xVFRqNFQySk80MnVENUlEOWU4OW9hMHNMS2hKWUQwWV9rcXhEdjNJM1hNdy9lZGl0IyE=\">Scalable Go Scheduler Design Doc</span>”</li>\n</ul>\n<h3 id=\"gmp-调度模型\"><a class=\"markdownIt-Anchor\" href=\"#gmp-调度模型\">#</a> GMP 调度模型</h3>\n<p>在  <code>go 1.2</code>  版本及以后，go 引入  <code>GMP</code>  调度模型</p>\n<h4 id=\"g-2\"><a class=\"markdownIt-Anchor\" href=\"#g-2\">#</a> G</h4>\n<p><code>goroutine</code>  的缩写，每次  <code>go func()</code>  都代表一个  <code>G</code> ，无限制。 使用  <code>struct runtime.g</code> ，包含了当前  <code>goroutine</code>  的状态、堆栈、上下文。</p>\n<h4 id=\"m-2\"><a class=\"markdownIt-Anchor\" href=\"#m-2\">#</a> M</h4>\n<p>工作线程 ( <code>OS thread</code> ) 也被称为 Machine，使用  <code>struct runtime.m</code> ，所有  <code>M</code>  是有线程栈的。 如果不对该线程栈提供内存的话，系统会给该线程栈提供内存 (不同操作系统提供的线程栈大小不同)<br>\n。当指定了线程栈，则  <code>M.stack→G.stack</code> ， <code>M</code>  的  <code>PC</code>  寄存器指向  <code>G</code>  提供的函数，然后去执行。</p>\n<h4 id=\"p\"><a class=\"markdownIt-Anchor\" href=\"#p\">#</a> P</h4>\n<p><code>“Processor”</code>  是一个抽象的概念，并不是真正的物理  <code>CPU</code> 。</p>\n<p><code>Dmitry Vyukov</code>  的方案是引入一个结构  <code>P</code> ，它代表了  <code>M</code>  所需的上下文环境，也是处理用户级代码逻辑的处理器。它负责衔接  <code>M</code>  和  <code>G</code>  的调度上下文，将等待执行的  <code>G</code>  与  <code>M</code>  对接。当 P 有任务时需要创建或者唤醒一个  <code>M</code>  来执行它队列里的任务。所以  <code>P/M</code>  需要进行绑定，构成一个执行单元。  <code>P</code>  决定了并行任务的数量，可通过  <code>runtime.GOMAXPROCS</code>  来设定。在  <code>Go1.5</code>  之后  <code>GOMAXPROCS</code>  被默认设置可用的核数，而之前则默认为 <code>1</code> 。</p>\n<p><code>Runtime</code>  起始时会启动一些  <code>G</code> ：垃圾回收的  <code>G</code> ，执行调度的  <code>G</code> ，运行用户代码的  <code>G</code> ；并且会创建一个  <code>M</code>  用来开始  <code>G</code>  的运行。随着时间的推移，更多的  <code>G</code>  会被创建出来，更多的  <code>M</code>  也会被创建出来。</p>\n<p>Tips: <span class=\"exturl\" data-url=\"aHR0cHM6Ly9naXRodWIuY29tL3ViZXItZ28vYXV0b21heHByb2Nz\">https://github.com/uber-go/automaxprocs</span><br>\n <code>Automatically set GOMAXPROCS to match Linux container CPU quota.</code> <br>\n <code>mcache/stackalloc</code>  从  <code>M</code>  移到了  <code>P</code> ，而  <code>G</code>  队列也被分成两类，保留全局  <code>G</code>  队列，同时每个  <code>P</code>  中都会有一个本地的  <code>G</code>  队列。</p>\n<h4 id=\"gmp-调度\"><a class=\"markdownIt-Anchor\" href=\"#gmp-调度\">#</a>  <code>GMP</code>  调度</h4>\n<p><code>GMP</code>  调度模型，引入了  <code>local queue</code> ，因为  <code>P</code>  的存在， <code>runtime</code>  并不需要做一个集中式的  <code>goroutine</code>  调度，每一个  <code>M</code>  都会在  <code>P's local queue</code> 、 <code>global queue</code>  或者其他  <code>P</code>  队列中找  <code>G</code>  执行，减少全局锁对性能的影响。<br>\n这也是  <code>GMP Work-stealing</code>  调度算法的核心。注意  <code>P</code>  的本地  <code>G</code>  队列还是可能面临一个并发访问的场景，为了避免加锁，这里  <code>P</code>  的本地队列是一个  <code>LockFree</code>  的队列，窃取  <code>G</code>  时使用  <code>CAS</code>  原子操作来完成。关于 <code>LockFree</code>  和  <code>CAS</code>  的知识参见  <code>Lock-Free</code> 。</p>\n<p><img data-src=\"/images/go/13-49.png\" alt=\"\"></p>\n<h3 id=\"work-stealing\"><a class=\"markdownIt-Anchor\" href=\"#work-stealing\">#</a>  <code>Work Stealing</code></h3>\n<p>当一个  <code>P</code>  执行完本地所有的  <code>G</code>  之后，并且全局队列为空的时候，会尝试挑选一个受害者  <code>P</code>  ，从它的  <code>G</code>  队列中窃取一半的  <code>G</code> 。否则会从全局队列中获取 (当前个数 / <code>GOMAXPROCS</code> ) 个  <code>G</code>  。<br>\n为了保证公平性，从随机位置上的  <code>P</code>  开始，而且遍历的顺序也随机化了 (选择一个小于  <code>GOMAXPROCS</code>  ，且和它互为质数的步长)，保证遍历的顺序也随机化了。</p>\n<p><img data-src=\"/images/go/13-50.png\" alt=\"\"></p>\n<p>光窃取失败时获取是不够的，可能会导致全局队列饥饿。 <code>P</code>  的调度算法中还会每个  <code>N</code>  轮调度之后就去全局队列拿一个  <code>G</code> 。 如下图。</p>\n<p><img data-src=\"/images/go/13-52.png\" alt=\"\"></p>\n<h4 id=\"谁放入的全局队列呢\"><a class=\"markdownIt-Anchor\" href=\"#谁放入的全局队列呢\">#</a> 谁放入的全局队列呢</h4>\n<p>有两种情况会把 <code>G</code>  放到全局队列中。</p>\n<ul>\n<li>新建  <code>G</code>  时  <code>P</code>  的本地  <code>G</code>  队列放不下已满并达到 <code>256</code>  个的时候会放半数  <code>G</code>  到全局队列去。</li>\n<li>阻塞的系统调用返回时找不到空闲  <code>P</code>  也会放到全局队列。</li>\n</ul>\n<p><img data-src=\"/images/go/13-51.png\" alt=\"\"></p>\n<h3 id=\"syscall-系统调用\"><a class=\"markdownIt-Anchor\" href=\"#syscall-系统调用\">#</a> SysCall 系统调用</h3>\n<p>当  <code>G</code>  调用  <code>syscall</code>  后会解绑  <code>P</code> ，然后  <code>M</code>  和  <code>G</code>  进入阻塞，而  <code>P</code>  此时的状态就是  <code>syscall</code> ，表明这个  <code>P</code>  的  <code>G</code>  正在  <code>syscall</code>  中，这时的  <code>P</code>  是不能被调度给别的  <code>M</code>  的。如果在短时间内阻塞的  <code>M</code>  就唤醒了，那么  <code>M</code>  会优先来重新获取这个  <code>P</code> ，能获取到就继续绑回去，这样有利于数据的局部性。<br>\n系统监视器 ( <code>system monitor</code> )，称为  <code>sysmon</code> ，会定时扫描。在执行  <code>syscall</code>  时，如果某个  <code>P</code>  的  <code>G</code>  执行超过一个  <code>sysmon tick</code> ( <code>10ms</code> )，就会把他设为  <code>idle</code> ，重新调度给需要的  <code>M</code> ，强制解绑。</p>\n<p><img data-src=\"/images/go/13-53.png\" alt=\"\"></p>\n<p><code>P3</code>  和  <code>M</code>  脱离后目前在  <code>idle list</code>  中等待被绑定（处于  <code>syscall</code>  状态）。而  <code>syscall</code>  结束后  <code>M</code>  按照如下规则执行直到满足其中一个条件：</p>\n<ul>\n<li>尝试获取同一个  <code>P</code> ( <code>P3</code> )，恢复执行  <code>G</code></li>\n<li>尝试获取  <code>idle list</code>  中的其他空闲  <code>P</code> ，恢复执行  <code>G</code></li>\n<li>找不到空闲  <code>P</code> ，把  <code>G</code>  放回  <code>global queue</code> ， <code>M</code>  放回到  <code>idle list</code></li>\n</ul>\n<p>再举一个例子：<br>\n如下图.<br>\n<img data-src=\"/images/go/13-54.png\" alt=\"\"></p>\n<ul>\n<li>第一步：  <code>G35</code>  发生了系统调用，长时间没有返回。  <code>P1</code>  和  <code>M</code>  解绑。( <code>p1</code>  不会马上被推送到 <code>idle list</code> , 而是经过一段时间才会推送到 <code>idle list.</code> )</li>\n<li>第二步： <code>G35</code>  系统调用完成，将 <code>G35</code>  推向了全局队列.</li>\n<li>第三步： <code>G35</code>  被其他的 P 捞到了 (可能 <code>P0</code>  经过 <code>1/61</code>  轮次正好 <code>check</code>  全局队列)， 这样  <code>G35</code>  就可以继续执行了。</li>\n</ul>\n<p>需要注意的是： 当使用了  <code>Syscall</code> ， <code>Go</code>  无法限制  <code>Blocked OS threads</code>  的数量：<br>\n <code>The GOMAXPROCS variable limits the number of operating system threads that can execute user-level Go code simultaneously. There is no limit to the number of threads that can be blocked in system calls on behalf of Go code; those do not count against the GOMAXPROCS limit. This package’s GOMAXPROCS function queries and changes the limit.</code></p>\n<p><code>Tips</code> : 使用  <code>syscall</code>  写程序要认真考虑  <code>pthread exhaust</code>  问题。</p>\n<h3 id=\"spining-thread\"><a class=\"markdownIt-Anchor\" href=\"#spining-thread\">#</a> Spining Thread.</h3>\n<p>线程自旋是相对于线程阻塞而言的，表象就是循环执行一个指定逻辑 (调度逻辑，目的是不停地寻找 G)。这样做的问题显而易见，如果  <code>G</code>  迟迟不来， <code>CPU</code>  会白白浪费在这无意义的计算上。但好处也很明显，降低了 M 的上下文切换成本，提高了性能。在两个地方引入自旋：</p>\n<ul>\n<li>类型 1:  <code>M</code>  不带  <code>P</code>  的找  <code>P</code>  挂载（一有  <code>P</code>  释放就结合）</li>\n<li>类型 2:  <code>M</code>  带  <code>P</code>  的找  <code>G</code>  运行（一有  <code>runable</code>  的  <code>G</code>  就执行）。 这种情况下会首先 按照  <code>1/61</code>  轮次的查询  <code>global Queue</code>  , 然后再查看  <code>local Queue</code>  是否有  <code>G</code> . 如果没有，则去查看  <code>Global Queue</code> , 如果没有在去检查   <code>net poller</code> , 看看是否有可用的  <code>goroutine</code> .<br>\n 为了避免过多浪费  <code>CPU</code>  资源，自旋的  <code>M</code>  最多只允许  <code>GOMAXPROCS</code>  ( <code>Busy P</code> )。同时当有类型 1 的自旋  <code>M</code>  存在时，类型 <code>2</code>  的自旋  <code>M</code>  就不阻塞，阻塞会释放  <code>P</code> ，一释放  <code>P</code>  就马上被类型 <code>1</code>  的自旋  <code>M</code>  抢走了，没必要。</li>\n</ul>\n<p>在新  <code>G</code>  被创建、 <code>M</code>  进入系统调用、 <code>M</code>  从空闲被激活这三种状态变化前，调度器会确保至少有一个自旋  <code>M</code>  存在（唤醒或者创建一个  <code>M</code> ），除非没有空闲的  <code>P</code> 。</p>\n<p>为什么呢？</p>\n<ul>\n<li>当新  <code>G</code>  创建，如果有可用  <code>P</code> ，就意味着新  <code>G</code>  可以被立即执行，即便不在同一个  <code>P</code>  也无妨，所以我们保留一个自旋的 M（这时应该不存在类型 1 的自旋只有类型 2 的自旋）就可以保证新 G 很快被运行。</li>\n<li>当  <code>M</code>  进入系统调用，意味着  <code>M</code>  不知道何时可以醒来，那么  <code>M</code>  对应的  <code>P</code>  中剩下的  <code>G</code>  就得有新的  <code>M</code>  来执行，所以我们保留一个自旋的  <code>M</code>  来执行剩下的  <code>G</code> （这时应该不存在类型 <code>2</code>  的自旋只有类型 <code>1</code>  的自旋）。</li>\n<li>如果  <code>M</code>  从空闲变成活跃，意味着可能一个处于自旋状态的  <code>M</code>  进入工作状态了，这时要检查并确保还有一个自旋  <code>M</code>  存在，以防还有  <code>G</code>  或者还有  <code>P</code>  空着的。</li>\n</ul>\n<h3 id=\"gmp-模型问题总结\"><a class=\"markdownIt-Anchor\" href=\"#gmp-模型问题总结\">#</a>  <code>GMP</code>  模型问题总结</h3>\n<ul>\n<li>单一全局互斥锁 ( <code>Sched.Lock</code> ) 和集中状态存储<br>\n <code>G</code>  被分成全局队列和  <code>P</code>  的本地队列，全局队列依旧是全局锁，但是使用场景明显很少， <code>P</code>  本地队列使用无锁队列，使用原子操作来面对可能的并发场景。</li>\n<li><code>Goroutine</code>  传递问题<br>\n <code>G</code>  创建时就在  <code>P</code>  的本地队列，可以避免在  <code>G</code>  之间传递（窃取除外）， <code>G</code>  对  <code>P</code>  的数据局部性好；当  <code>G</code>  开始执行了，系统调用返回后  <code>M</code>  会尝试获取可用  <code>P</code> ，获取到了的话可以避免在  <code>M</code>  之间传递。而且优先获取调用阻塞前的  <code>P</code> ，所以  <code>G</code>  对  <code>M</code>  数据局部性好， <code>G</code>  对  <code>P</code>  的数据局部性也好。</li>\n<li><code>Per-M</code>  持有内存缓存 ( <code>M.mcache</code> )<br>\n 内存  <code>mcache</code>  只存在  <code>P</code>  结构中， <code>P</code>  最多只有  <code>GOMAXPROCS</code>  个，远小于  <code>M</code>  的个数，所以内存没有过多的消耗。</li>\n<li>严重的线程阻塞 / 解锁<br>\n通过引入自旋，保证任何时候都有处于等待状态的自旋 M，避免在等待可用的  <code>P</code>  和  <code>G</code>  时频繁的阻塞和唤醒。</li>\n</ul>\n<h3 id=\"syscon\"><a class=\"markdownIt-Anchor\" href=\"#syscon\">#</a> syscon</h3>\n<p><code>sysmon</code>  也叫监控线程，它<b>无需  <code>P</code>  也可以运行</b>，他是一个死循环，每 <code>20us~10ms</code>  循环一次，循环完一次就  <code>sleep</code>  一会，为什么会是一个变动的周期呢，主要是避免空转，如果每次循环都没什么需要做的事，那么  <code>sleep</code>  的时间就会加大。</p>\n<ul>\n<li>释放闲置超过 <code>5</code>  分钟的  <code>span</code>  物理内存；</li>\n<li>如果超过 2 分钟没有垃圾回收，强制执行；</li>\n<li>将长时间未处理的  <code>netpoll</code>  添加到全局队列；</li>\n<li>向长时间运行的  <code>G</code>  任务发出抢占调度；</li>\n<li>收回因  <code>syscall</code>  长时间阻塞的  <code>P</code> ；</li>\n</ul>\n<p><img data-src=\"/images/go/13-55.png\" alt=\"\"></p>\n<p>当  <code>P</code>  在  <code>M</code>  上执行时间超过 <code>10ms</code> ， <code>sysmon</code>  调用  <code>preemptone</code>  将  <code>G</code>  标记为  <code>stackPreempt</code>  。因此需要在某个地方触发检测逻辑， <code>Go</code>  当前是在检查栈是否溢出的地方判定 ( <code>morestack()</code> )， <code>M</code>  会保存当前  <code>G</code>  的上下文，重新进入调度逻辑，这样就不会死循环了。<br>\n死循环：<span class=\"exturl\" data-url=\"aHR0cHM6Ly9naXRodWIuY29tL2dvbGFuZy9nby9pc3N1ZXMvMTE0NjI=\">issues/11462</span><br>\n 信号抢占：<span class=\"exturl\" data-url=\"aHR0cDovL3hpYW9ydWkuY2MvYXJjaGl2ZXMvNjUzNQ==\">go1.14 基于信号的抢占式调度实现原理</span><br>\n异步抢占，注册  <code>sigurg</code>  信号，通过  <code>sysmon</code>  检测，对  <code>M</code>  对应的线程发送信号，触发注册的  <code>handler</code> ，它往当前  <code>G</code>  的  <code>PC</code>  中插入一条指令 (调用某个方法)，在处理完  <code>handler</code> ， <code>G</code>  恢复后，自己把自己推到了  <code>global queue</code>  中。<br>\n<img data-src=\"/images/go/13-56.png\" alt=\"\"></p>\n<h3 id=\"network-poller\"><a class=\"markdownIt-Anchor\" href=\"#network-poller\">#</a> Network poller</h3>\n<p><code>Go</code>  所有的  <code>I/O</code>  都是阻塞的。然后通过  <code>goroutine + channel</code>  来处理并发。因此所有的  <code>IO</code>  逻辑都是直来直去的，你不再需要回调，不再需要  <code>future</code> ，要的仅仅是  <code>step by step</code> 。这对于代码的可读性是很有帮助的。<br>\n <code>G</code>  发起网络  <code>I/O</code>  操作也不会导致  <code>M</code>  被阻塞 (仅阻塞 <code>G</code> )，从而不会导致大量  <code>M</code>  被创建出来。将异步  <code>I/O</code>  转换为阻塞  <code>I/O</code>  的部分称为  <code>netpoller</code> 。打开或接受连接都被设置为非阻塞模式。如果你试图对其进行  <code>I/O</code>  操作，并且文件描述符数据还没有准备好， <code>G</code>  会进入  <code>gopark</code>  函数，将当前正在执行的  <code>G</code>  状态保存起来，然后切换到新的堆栈上执行新的  <code>G</code> 。</p>\n<p><img data-src=\"/images/go/13-57.png\" alt=\"\"></p>\n<p>那什么时候  <code>G</code>  被调度回来呢？</p>\n<ul>\n<li><code>sysmon</code></li>\n<li><code>schedule()</code> ： <code>M</code>  找  <code>G</code>  的调度函数</li>\n<li><code>GC</code> ： <code>start the world</code> <br>\n 调用  <code>netpoll()</code>  在某一次调度  <code>G</code>  的过程中，处于就绪状态的  <code>fd</code>  对应的  <code>G</code>  就会被调度回来。<br>\n <code>G</code>  的  <code>gopark</code>  状态： <code>G</code>  置为  <code>waiting</code>  状态，等待显示  <code>goready</code>  唤醒，在  <code>poller</code>  中用得较多，还有锁、 <code>chan</code>  等。</li>\n</ul>\n<p><img data-src=\"/images/go/13-58.png\" alt=\"\"></p>\n<h3 id=\"scheduler-affinity-调度亲和性\"><a class=\"markdownIt-Anchor\" href=\"#scheduler-affinity-调度亲和性\">#</a> Scheduler Affinity 调度亲和性</h3>\n<p><img data-src=\"/images/go/13-59.png\" alt=\"\"></p>\n<p><code>GM</code>  调度器时代的， <code>chan</code>  操作导致的切换代价。</p>\n<ul>\n<li><code>Goroutine#7</code>  正在等待消息，阻塞在  <code>chan</code> 。一旦收到消息，这个  <code>goroutine</code>  就被推到全局队列。</li>\n<li>然后， <code>chan</code>  推送消息， <code>goroutine#X</code>  将在可用线程上运行，而  <code>goroutine#8</code>  将阻塞在  <code>chan</code> 。</li>\n<li><code>goroutine#7</code>  现在在可用线程上运行。<br>\n在  <code>chan</code>  来回通信的  <code>goroutine</code>  会导致频繁的  <code>blocks</code> ，即频繁地在本地队列中重新排队。然而，由于本地队列是  <code>FIFO</code>  实现，如果另一个  <code>goroutine</code>  占用线程， <code>unblock goroutine</code>  不能保证尽快运行。同时  <code>Go</code>  亲缘性调度的一些限制： <code>Work-stealing</code> 、系统调用。<br>\n <code>goroutine #9</code>  在  <code>chan</code>  被阻塞后恢复。但是，它必须等待 <code>#2</code> 、 <code>#5</code>  和 <code>#4</code>  之后才能运行。 <code>goroutine #5</code>  将阻塞其线程，从而延迟 <code>goroutine #9</code> ，并使其面临被另一个  <code>P</code>  窃取的风险。<br>\n<img data-src=\"/images/go/13-60.png\" alt=\"\"></li>\n</ul>\n<p>针对  <code>communicate-and-wait</code>  模式，进行了亲缘性调度的优化。 <code>Go 1.5</code>  在  <code>P</code>  中引入了  <code>runnext</code>  特殊的一个字段，可以高优先级执行  <code>unblock G</code> 。<br>\n <code>goroutine #9</code>  现在被标记为下一个可运行的。这种新的优先级排序允许  <code>goroutine</code>  在再次被阻塞之前快速运行。这一变化对运行中的标准库产生了总体上的积极影响，提高了一些包的性能。<br>\n<img data-src=\"/images/go/13-61.png\" alt=\"\"></p>\n<h2 id=\"goroutine-lifecycle\"><a class=\"markdownIt-Anchor\" href=\"#goroutine-lifecycle\">#</a> Goroutine Lifecycle</h2>\n<h3 id=\"go-程序的启动\"><a class=\"markdownIt-Anchor\" href=\"#go-程序的启动\">#</a> go 程序的启动</h3>\n<p><img data-src=\"/images/go/13-62.png\" alt=\"\"></p>\n<p>整个程序始于一段汇编，而在随后的 runtime・rt0_go（也是汇编程序）中，会执行很多初始化工作。</p>\n<p><img data-src=\"/images/go/13-63.png\" alt=\"\"></p>\n<ul>\n<li>绑定 m0 和 g0，m0 就是程序的主线程，程序启动必然会拥有一个主线程，这个就是 m0。g0 负责调度，即 shedule () 函数。</li>\n<li>创建 P，绑定 m0 和 p0，首先会创建 GOMAXPROCS 个 P ，存储在 sched 的 空闲链表 (pidle)。</li>\n<li>新建任务 g 到 p0 本地队列，m0 的 g0 会创建一个 指向 runtime.main () 的 g ，并放到 p0 的本地队列。<br>\nruntime.main (): 启动 sysmon 线程；启动 GC 协程；执行 init，即代码中的各种 init 函数；执行 main.main 函数。</li>\n</ul>\n<h4 id=\"os-thread-创建\"><a class=\"markdownIt-Anchor\" href=\"#os-thread-创建\">#</a> Os Thread 创建</h4>\n<p>准备运行的新 goroutine 将唤醒 P 以更好地分发工作。这个 P 将创建一个与之关联的 M 绑定到一个 OS thread。<br>\n<img data-src=\"/images/go/13-64.png\" alt=\"\"><br>\n<img data-src=\"/images/go/13-66.png\" alt=\"\"></p>\n<p><code>go func()</code>  中 触发  <code>Wakeup</code>  唤醒机制：<br>\n有空闲的  <code>P</code>  而没有在  <code>spinning</code>  状态的 M 时候，需要去唤醒一个空闲 (睡眠) 的  <code>M</code>  或者新建一个。当线程首次创建时，会执行一个特殊的  <code>G</code> ，即  <code>g0</code> ，它负责管理和调度  <code>G</code> 。<br>\n<img data-src=\"/images/go/13-65.png\" alt=\"\"></p>\n<h4 id=\"特殊的g0\"><a class=\"markdownIt-Anchor\" href=\"#特殊的g0\">#</a> 特殊的 g0</h4>\n<p><code>Go</code>  基于两种断点将  <code>G</code>  调度到线程上：</p>\n<ul>\n<li>当  <code>G</code>  阻塞时：系统调用、互斥锁或  <code>chan</code> 。阻塞的  <code>G</code>  进入睡眠模式 / 进入队列，并允许  <code>Go</code>  安排和运行等待其他的  <code>G</code> 。</li>\n<li>在函数调用期间，如果  <code>G</code>  必须扩展其堆栈。这个断点允许  <code>Go</code>  调度另一个  <code>G</code>  并避免运行  <code>G</code>  占用  <code>CPU</code> 。<br>\n在这两种情况下，运行调度程序的  <code>g0</code>  将当前  <code>G</code>  替换为另一个  <code>G</code> ，即  <code>ready to run</code> 。然后，选择的  <code>G</code>  替换  <code>g0</code>  并在线程上运行。与常规  <code>G</code>  相反， <code>g0</code>  有一个固定和更大的栈。</li>\n<li><code>Defer</code>  函数的分配</li>\n<li><code>GC</code>  收集，比如  <code>STW</code> 、扫描  <code>G</code>  的堆栈和标记、清除操作</li>\n<li>栈扩容，当需要的时候，由  <code>g0</code>  进行扩栈操作</li>\n</ul>\n<p><img data-src=\"/images/go/13-67.png\" alt=\"\"></p>\n<h4 id=\"schedule\"><a class=\"markdownIt-Anchor\" href=\"#schedule\">#</a> Schedule</h4>\n<p>在  <code>Go</code>  中， <code>G</code>  的切换相当轻便，其中需要保存的状态仅仅涉及以下两个：</p>\n<ul>\n<li><code>Goroutine</code>  在停止运行前执行的指令，程序当前要运行的指令是记录在程序计数器（ <code>PC</code> ）中的，  <code>G</code>  稍后将在同一指令处恢复运行；</li>\n<li><code>G</code>  的堆栈，以便在再次运行时还原局部变量；在切换之前，堆栈将被保存，以便在  <code>G</code>  再次运行时进行恢复：</li>\n</ul>\n<p><img data-src=\"/images/go/13-68.png\" alt=\"\"><br>\n<img data-src=\"/images/go/13-69.png\" alt=\"\"><br>\n<img data-src=\"/images/go/13-70.png\" alt=\"\"><br>\n<img data-src=\"/images/go/13-71.png\" alt=\"\"></p>\n<p>从  <code>g</code>  到  <code>g0</code>  或从  <code>g0</code>  到  <code>g</code>  的切换是相当迅速的，它们只包含少量固定的指令 ( <code>9-10ns</code> )。相反，对于调度阶段，调度程序需要检查许多资源以便确定下一个要运行的  <code>G</code> 。<br>\n当前  <code>g</code>  阻塞在 chan 上并切换到  <code>g0</code> ：</p>\n<ul>\n<li>1、PC 和堆栈指针一起保存在内部结构中；</li>\n<li>2、将 g0 设置为正在运行的 goroutine；</li>\n<li>3、g0 的堆栈替换当前堆栈；</li>\n</ul>\n<p><code>g0</code>  寻找新的  <code>Goroutine</code>  来运行<br>\n <code>g0</code>  使用所选的  <code>Goroutine</code>  进行切换：</p>\n<ul>\n<li>1、 <code>PC</code>  和堆栈指针是从其内部结构中获取的；</li>\n<li>2、程序跳转到对应的  <code>PC</code>  地址；</li>\n</ul>\n<p><img data-src=\"/images/go/13-72.png\" alt=\"\"></p>\n<h3 id=\"goroutine-recycle\"><a class=\"markdownIt-Anchor\" href=\"#goroutine-recycle\">#</a> Goroutine Recycle</h3>\n<p><code>goroutine</code>  重用</p>\n<p><code>G</code>  很容易创建，栈很小以及快速的上下文切换。基于这些原因，开发人员非常喜欢并使用它们。然而，一个产生许多  <code>shortlive</code>  的  <code>G</code>  的程序将花费相当长的时间来创建和销毁它们。<br>\n每个  <code>P</code>  维护一个  <code>freelist G</code> ，保持这个列表是本地的，这样做的好处是不使用任何锁来  <code>push/get</code>  一个空闲的  <code>G</code> 。当  <code>G</code>  退出当前工作时，它将被  <code>push</code>  到这个空闲列表中。</p>\n<p><img data-src=\"/images/go/13-73.png\" alt=\"\"></p>\n<p>为了更好地分发空闲的  <code>G</code>  ，调度器也有自己的列表。它实际上有两个列表：一个包含已分配栈的  <code>G</code> ，另一个包含释放过堆栈的  <code>G</code> （无栈）。<br>\n锁保护  <code>central list</code> ，因为任何 M 都可以访问它。当本地列表长度超过 64 时，调度程序持有的列表从  <code>P</code>  获取  <code>G</code> 。然后一半的  <code>G</code>  将移动到中心列表 ( <code>central list</code> )。需求回收  <code>G</code>  是一种节省分配成本的好方法。但是，由于堆栈是动态增长的，现有的 <code>G</code>  最终可能会有一个大栈。因此，<b>当堆栈增长（即超过 <code>2K</code> ）时， <code>Go</code>  不会保留这些栈。</b></p>\n<p><img data-src=\"/images/go/13-74.png\" alt=\"\"></p>\n<h2 id=\"references\"><a class=\"markdownIt-Anchor\" href=\"#references\">#</a> References</h2>\n<p><span class=\"exturl\" data-url=\"aHR0cHM6Ly9sZWFybmt1LmNvbS9hcnRpY2xlcy80MTcyOA==\">https://learnku.com/articles/41728</span></p>\n",
            "tags": [
                "go",
                "go-runtimes"
            ]
        }
    ]
}