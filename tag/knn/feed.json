{
    "version": "https://jsonfeed.org/version/1",
    "title": "方家小白 • All posts by \"knn\" tag",
    "description": "和你一起遇见更好的自己",
    "home_page_url": "https://fangjiaxiaobai.github.io",
    "items": [
        {
            "id": "https://fangjiaxiaobai.github.io/2021/10/29/machine-learn/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A002-K-%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%95/",
            "url": "https://fangjiaxiaobai.github.io/2021/10/29/machine-learn/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A002-K-%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%95/",
            "title": "K-近邻算法(KNN)",
            "date_published": "2021-10-29T10:18:00.000Z",
            "content_html": "<p><code>k-近邻算法</code> ，英文名:  <code>K Nearest Neighbor</code>  算法  又叫 <code>KNN算法</code> ，这个算法是机器学习里面一个比较经典的算法， 总体来说 1 算法是相对比较容易理解的算法.</p>\n<h2 id=\"定义\"><a class=\"markdownIt-Anchor\" href=\"#定义\">#</a> 定义</h2>\n<p>如果一个样本在特征空间中的 k 个最相似 (即特征空间中最邻近) 的样本中的大多数属于某一个类别，则该样本也属于这个类别。</p>\n<blockquote>\n<p><code>KNN</code>  算法最早是由 <code>Cover</code>  和 <code>Hart</code>  提出的一种分类算法。应用场景有字符识别、文本分类、图像识别等领域。</p>\n</blockquote>\n<h2 id=\"算法的理解\"><a class=\"markdownIt-Anchor\" href=\"#算法的理解\">#</a> 算法的理解</h2>\n<p>举一个例子来，来分析一下  <code>KNN</code>  算法的实现原理</p>\n<p>假设我们现在有几部电影，如下图:</p>\n<p><img data-src=\"/images/ml/02-knn-1.png\" alt=\"\"></p>\n<p>我们要 根据 搞笑镜头，拥抱镜头，打斗镜头的个数 这三个特征来预测出 《唐人街探案》所属的电影类型.</p>\n<p>我们使用  <code>KNN算法</code>  思想来实现预测。</p>\n<p>将样本中特征作为坐标抽，建立坐标系。从而建立特征空间。本例中，分别把 搞笑镜头，拥抱镜头，打斗镜头 作为 <code>x,y,z</code>  轴。然后把计算出每个样本和 《唐人街探案》 的距离，选择距离最近的前 k 个 ( <code>KNN中的k</code> ) 样本，这 <code>k</code>  个样本大多数所属的电影类别就是 《唐人街探案》的电影类型。</p>\n<blockquote>\n<p>特征空间：是指已特征为坐标轴简历的一种特征的坐标系，可能是多维的。</p>\n</blockquote>\n<p>那你可能对 距离 是如何计算的，有点疑惑。计算距离的方式有很多种。<br>\n先学习一下最简单的 欧氏距离。(初中都学过的！)</p>\n<p>在二维坐标系中， 我们可以使用一下方式来计算出两个点的距离。</p>\n<p><img data-src=\"/images/ml/02-knn-2.png\" alt=\"\"></p>\n<p>在多维的特征空间中，我们也可以使用同样的方式来计算欧式距离。如下图：</p>\n<p><img data-src=\"/images/ml/02-knn-3.png\" alt=\"\"></p>\n<p>那计算一下样本集中的欧式距离，如下图:</p>\n<p><img data-src=\"/images/ml/02-knn-4.png\" alt=\"\"></p>\n<p>并计算出了最近的 5 个样本中有三个喜剧片类型，2 两个爱情片类型。 那根据 <code>KNN</code>  就是喜剧片类型。</p>\n<p>这就是 <code>KNN算法</code> 的核心思想了。</p>\n<p>这个例子中，我们选则了 最近的 <code>5</code>  个样本，也就是 k=5 的时候，会有三个喜剧片类型，两个爱情片类型。这个 <code>5</code>  是如何选择的呢？</p>\n<h2 id=\"k值的选择\"><a class=\"markdownIt-Anchor\" href=\"#k值的选择\">#</a> k 值的选择</h2>\n<p><code>K值</code> 选择问题，李航博士的一书「统计学习方法」上所说：</p>\n<ol>\n<li>\n<p>选择较小的 <code>K</code>  值，就相当于用较小的领域中的训练实例进行预测，“学习” 近似误差会减小，只有与输入实例较近或相似的训练实例才会对预测结果起作用，与此同时带来的问题是 “学习” 的估计误差会增大，换句话说， <code>K值</code> 的减小就意味着整体模型变得复杂，容易发生过拟合；</p>\n</li>\n<li>\n<p>选择较大的 <code>K值</code> ，就相当于用较大领域中的训练实例进行预测，其优点是可以减少学习的估计误差，但缺点是学习的近似误差会增大。这时候，与输入实例较远（不相似的）训练实例也会对预测器作用，使预测发生错误，且 K 值的增大就意味着整体的模型变得简单。</p>\n</li>\n<li>\n<p><code>K=N</code> （ <code>N</code>  为训练样本个数），则完全不足取，因为此时无论输入实例是什么，都只是简单的预测它属于在训练实例中最多的类，模型过于简单，忽略了训练实例中大量有用信息。</p>\n</li>\n</ol>\n<p>在实际应用中， <code>K值</code> 一般取一个比较小的数值，例如采用交叉验证法 ( <code>cross validation</code> )（简单来说，就是把训练数据在分成两组：训练集和验证集）来选择最优的 K 值。对这个简单的分类器进行泛化，用核方法把这个线性模型扩展到非线性的情况，具体方法是把低维数据集映射到高维特征空间。</p>\n<h2 id=\"knn的优化\"><a class=\"markdownIt-Anchor\" href=\"#knn的优化\">#</a> KNN 的优化</h2>\n<p><code>KNN</code>  算法需要计算所有的样本数据和预测数据的距离，需要选择出距离预测数据最近的 k 个样本数据的预测归类。在庞大的数据量面前，计算所有样本数据距离，显然是不可取的。为了避免每次都重新计算一遍距离， <code>KNN</code>  算法提供了多种优化方法， 比如  <code>KD-tree</code> ,  <code>ball_tree</code> ,  <code>brute</code> . 这几种优化方式的具体实现逻辑，我会在后面的几篇文章中挨个分析。</p>\n<h2 id=\"距离的计算\"><a class=\"markdownIt-Anchor\" href=\"#距离的计算\">#</a> 距离的计算</h2>\n<p><code>KNN</code>  算法，最重要的就是距离。 除了上文提到的欧式距离，还有其他计算距离的方法吗？</p>\n<p>有。</p>\n<p>除了欧式距离，还有 曼哈顿距离，</p>\n<h3 id=\"曼哈顿距离\"><a class=\"markdownIt-Anchor\" href=\"#曼哈顿距离\">#</a> 曼哈顿距离</h3>\n<p>在曼哈顿街区要从一个十字路口开车到另一个十字路口，驾驶距离显然不是两点间的直线距离。这个实际驾驶距离就是 “曼哈顿距离”。曼哈顿距离也称为 “城市街区距离”( <code>City Block distance</code> )。如下图:<br>\n<img data-src=\"/images/ml/02-knn-6.png\" alt=\"\"></p>\n<p>计算公式见下图:</p>\n<p><img data-src=\"/images/ml/02-knn-7.png\" alt=\"\"></p>\n<h3 id=\"切比雪夫距离-chebyshev-distance\"><a class=\"markdownIt-Anchor\" href=\"#切比雪夫距离-chebyshev-distance\">#</a> 切比雪夫距离 (Chebyshev Distance)</h3>\n<p>国际象棋中，国王可以直行、横行、斜行，所以国王走一步可以移动到相邻 8 个方格中的任意一个。国王从格子 <code>(x1,y1)</code>  走到格子 <code>(x2,y2)</code>  最少需要多少步？这个距离就叫切比雪夫距离。</p>\n<p><img data-src=\"/images/ml/02-knn-8.png\" alt=\"\"></p>\n<p>计算公式见下图:</p>\n<p><img data-src=\"/images/ml/02-knn-9.png\" alt=\"\"></p>\n<h3 id=\"闵可夫斯基距离minkowski-distance\"><a class=\"markdownIt-Anchor\" href=\"#闵可夫斯基距离minkowski-distance\">#</a> 闵可夫斯基距离 (Minkowski Distance)</h3>\n<p>闵氏距离不是一种距离，而是一组距离的定义，是对多个距离度量公式的概括性的表述。</p>\n<p>两个 n 维变量 <code>a(x11,x12,…,x1n)</code>  与 <code>b(x21,x22,…,x2n)</code>  间的闵可夫斯基距离定义为：</p>\n<p><img data-src=\"/images/ml/02-knn-10.png\" alt=\"\"></p>\n<p>其中 <code>p</code>  是一个变参数：<br>\n当 <code>p=1</code>  时，就是曼哈顿距离；<br>\n当 <code>p=2</code>  时，就是欧氏距离；<br>\n当 <code>p→∞</code> 时，就是切比雪夫距离。</p>\n<p>根据 p 的不同，闵氏距离可以表示某一类 / 种的距离。</p>\n<p>小结：<br>\n1 闵氏距离，包括曼哈顿距离、欧氏距离和切比雪夫距离都存在明显的缺点:<br>\n <code>e.g.</code>  二维样本 (身高 <code>[单位:cm]</code> , 体重 <code>[单位:kg]</code> ), 现有三个样本： <code>a(180,50)</code> ， <code>b(190,50)</code> ， <code>c(180,60)</code> 。<br>\n <code>a</code>  与 <code>b</code>  的闵氏距离（无论是曼哈顿距离、欧氏距离或切比雪夫距离）等于 <code>a</code>  与 <code>c</code>  的闵氏距离。但实际上身高的 <code>10cm</code>  并不能和体重的 <code>10kg</code>  划等号。</p>\n<p>2 闵氏距离的缺点：<br>\n​ (1) 将各个分量的量纲 ( <code>scale</code> )，也就是 “单位” 相同的看待了；<br>\n​ (2) 未考虑各个分量的分布（期望，方差等）可能是不同的。</p>\n<h3 id=\"标准化欧氏距离-standardized-euclideandistance\"><a class=\"markdownIt-Anchor\" href=\"#标准化欧氏距离-standardized-euclideandistance\">#</a> 标准化欧氏距离 (Standardized EuclideanDistance)</h3>\n<p>标准化欧氏距离是针对欧氏距离的缺点而作的一种改进。</p>\n<p>思路：既然数据各维分量的分布不一样，那先将各个分量都 “标准化” 到均值、方差相等。假设样本集 X 的均值 ( <code>mean</code> ) 为 <code>m</code> ，标准差 ( <code>standard deviation</code> ) 为 <code>s</code> ， <code>X</code>  的 “标准化变量” 表示为：</p>\n<p><img data-src=\"/images/ml/02-knn-11.png\" alt=\"\"></p>\n<p>如果将方差的倒数看成一个权重，也可称之为加权欧氏距离 ( <code>Weighted Euclidean distance</code> )。</p>\n<h3 id=\"余弦距离cosine-distance\"><a class=\"markdownIt-Anchor\" href=\"#余弦距离cosine-distance\">#</a> 余弦距离 (Cosine Distance)</h3>\n<p>几何中，夹角余弦可用来衡量两个向量方向的差异；机器学习中，借用这一概念来衡量样本向量之间的差异。</p>\n<p>二维空间中向量 <code>A(x1,y1)</code>  与向量 <code>B(x2,y2)</code>  的夹角余弦公式：<br>\n<img data-src=\"/images/ml/02-knn-12.png\" alt=\"\"></p>\n<p>两个 <code>n</code>  维样本点 <code>a(x11,x12,…,x1n)</code>  和 <code>b(x21,x22,…,x2n)</code>  的夹角余弦为：</p>\n<p><img data-src=\"/images/ml/02-knn-13.png\" alt=\"\"></p>\n<p>即:</p>\n<p><img data-src=\"/images/ml/02-knn-14.png\" alt=\"\"></p>\n<p>夹角余弦取值范围为 <code>[-1,1]</code> 。余弦越大表示两个向量的夹角越小，余弦越小表示两向量的夹角越大。当两个向量的方向重合时余弦取最大值 <code>1</code> ，当两个向量的方向完全相反余弦取最小值 <code>-1</code></p>\n<h3 id=\"汉明距离hamming-distance\"><a class=\"markdownIt-Anchor\" href=\"#汉明距离hamming-distance\">#</a> 汉明距离 (Hamming Distance)</h3>\n<p>两个等长字符串 <code>s1</code>  与 <code>s2</code>  的汉明距离为：将其中一个变为另外一个所需要作的最小字符替换次数。</p>\n<p>例如：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">The Hamming distance between &quot;1011101&quot; and &quot;1001001&quot; is 2. </span><br><span class=\"line\">The Hamming distance between &quot;2143896&quot; and &quot;2233796&quot; is 3. </span><br><span class=\"line\">The Hamming distance between &quot;toned&quot; and &quot;roses&quot; is 3.</span><br></pre></td></tr></table></figure>\n<p><img data-src=\"/images/ml/02-knn-15.png\" alt=\"\"></p>\n<p>汉明重量：是字符串相对于同样长度的零字符串的汉明距离，也就是说，它是字符串中非零的元素个数：对于二进制字符串来说，就是  <code>1</code>  的个数，所以  <code>11101</code>  的汉明重量是  <code>4</code> 。因此，如果向量空间中的元素 <code>a</code>  和 <code>b</code>  之间的汉明距离等于它们汉明重量的差 <code>a-b</code> 。</p>\n<p>应用：汉明重量分析在包括信息论、编码理论、密码学等领域都有应用。比如在信息编码过程中，为了增强容错性，应使得编码间的最小汉明距离尽可能大。但是，如果要比较两个不同长度的字符串，不仅要进行替换，而且要进行插入与删除的运算，在这种场合下，通常使用更加复杂的编辑距离等算法。</p>\n<h3 id=\"杰卡德距离jaccard-distance\"><a class=\"markdownIt-Anchor\" href=\"#杰卡德距离jaccard-distance\">#</a> 杰卡德距离 (Jaccard Distance)</h3>\n<p>杰卡德相似系数 ( <code>Jaccard similarity coefficient</code> )：两个集合 <code>A</code>  和 <code>B</code>  的交集元素在 <code>A</code> ， <code>B</code>  的并集中所占的比例，称为两个集合的杰卡德相似系数，用符号 <code>J(A,B</code> ) 表示：</p>\n<p><img data-src=\"/images/ml/02-knn-16.png\" alt=\"\"></p>\n<p>杰卡德距离 ( <code>Jaccard Distance</code> )：与杰卡德相似系数相反，用两个集合中不同元素占所有元素的比例来衡量两个集合的区分度：</p>\n<p><img data-src=\"/images/ml/02-knn-17.png\" alt=\"\"></p>\n<h3 id=\"马氏距离mahalanobis-distance\"><a class=\"markdownIt-Anchor\" href=\"#马氏距离mahalanobis-distance\">#</a> 马氏距离 (Mahalanobis Distance)</h3>\n<p>下图有两个正态分布图，它们的均值分别为 <code>a</code>  和 <code>b</code> ，但方差不一样，则图中的 <code>A</code>  点离哪个总体更近？或者说 <code>A</code>  有更大的概率属于谁？显然， <code>A</code>  离左边的更近， <code>A</code>  属于左边总体的概率更大，尽管 <code>A</code>  与 <code>a</code>  的欧式距离远一些。这就是马氏距离的直观解释。</p>\n<p><img data-src=\"/images/ml/02-knn-18.png\" alt=\"\"></p>\n<p>马氏距离是基于样本分布的一种距离。</p>\n<p>马氏距离是由印度统计学家马哈拉诺比斯提出的，表示数据的协方差距离。它是一种有效的计算两个位置样本集的相似度的方法。</p>\n<p>与欧式距离不同的是，它考虑到各种特性之间的联系，即独立于测量尺度。</p>\n<p>马氏距离定义：设总体 <code>G</code>  为 <code>m</code>  维总体（考察 <code>m</code>  个指标），均值向量为 <code>μ=（μ1，μ2，… ...，μm，）</code> , 协方差阵为 <code>∑=（σij）</code> ,</p>\n<p>则样本 <code>X=（X1，X2，… …，Xm，）</code> 与总体 G 的马氏距离定义为：</p>\n<p><img data-src=\"/images/ml/02-knn-19.png\" alt=\"\"></p>\n<p>马氏距离也可以定义为两个服从同一分布并且其协方差矩阵为 <code>∑</code> 的随机变量的差异程度：如果协方差矩阵为单位矩阵，马氏距离就简化为欧式距离；如果协方差矩阵为对角矩阵，则其也可称为正规化的欧式距离。</p>\n<h4 id=\"马氏距离特性\"><a class=\"markdownIt-Anchor\" href=\"#马氏距离特性\">#</a> 马氏距离特性：</h4>\n<p>1. 量纲无关，排除变量之间的相关性的干扰；</p>\n<p>2. 马氏距离的计算是建立在总体样本的基础上的，如果拿同样的两个样本，放入两个不同的总体中，最后计算得出的两个样本间的马氏距离通常是不相同的，除非这两个总体的协方差矩阵碰巧相同；</p>\n<p>3 . 计算马氏距离过程中，要求总体样本数大于样本的维数，否则得到的总体样本协方差矩阵逆矩阵不存在，这种情况下，用欧式距离计算即可。</p>\n<p>4. 还有一种情况，满足了条件总体样本数大于样本的维数，但是协方差矩阵的逆矩阵仍然不存在，比如三个样本点 <code>(3,4)</code> ， <code>(5,6)</code> ， <code>(7,8)</code> ，这种情况是因为这三个样本在其所处的二维空间平面内共线。这种情况下，也采用欧式距离计算。</p>\n<h4 id=\"欧式距离马氏距离\"><a class=\"markdownIt-Anchor\" href=\"#欧式距离马氏距离\">#</a> 欧式距离 &amp; 马氏距离：</h4>\n<p><img data-src=\"/images/ml/02-knn-20.png\" alt=\"\"></p>\n<p>举例：</p>\n<p>已知有两个类 <code>G1</code>  和 <code>G2</code> ，比如 <code>G1</code>  是设备 <code>A</code>  生产的产品， <code>G2</code>  是设备 <code>B</code>  生产的同类产品。设备 <code>A</code>  的产品质量高（如考察指标为耐磨度 <code>X</code> ），其平均耐磨度 <code>μ1=80</code> ，反映设备精度的方差 <code>σ2(1)=0.25</code> ; 设备 B 的产品质量稍差，其平均耐磨损度 <code>μ2=75</code> ，反映设备精度的方差 <code>σ2(2)=4</code> .</p>\n<p>今有一产品 <code>G0</code> ，测的耐磨损度 <code>X0=78</code> ，试判断该产品是哪一台设备生产的？</p>\n<p>直观地看， <code>X0</code>  与 <code>μ1</code> （ <code>设备A</code> ）的绝对距离近些，按距离最近的原则，是否应把该产品判断 <code>设备A</code>  生产的？</p>\n<p>考虑一种相对于分散性的距离，记 <code>X0</code>  与 <code>G1</code> ， <code>G2</code>  的相对距离为 <code>d1</code> ， <code>d2</code> , 则：</p>\n<p><img data-src=\"/images/ml/02-knn-21.png\" alt=\"\"></p>\n<p>因为 <code>d2=1.5 &lt; d1=4</code> ，按这种距离准则，应判断 <code>X0</code>  为设备 B 生产的。</p>\n<p>设备 <code>B</code>  生产的产品质量较分散，出现 <code>X0</code>  为 <code>78</code>  的可能性较大；而 <code>设备A</code>  生产的产品质量较集中，出现 <code>X0</code>  为 <code>78</code>  的可能性较小。</p>\n<p>这种相对于分散性的距离判断就是马氏距离。</p>\n<p><img data-src=\"/images/ml/02-knn-22.png\" alt=\"\"></p>\n<h2 id=\"案例\"><a class=\"markdownIt-Anchor\" href=\"#案例\">#</a> 案例</h2>\n<h3 id=\"预测鸢尾花种类\"><a class=\"markdownIt-Anchor\" href=\"#预测鸢尾花种类\">#</a> 预测鸢尾花种类</h3>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> sklearn.datasets <span class=\"keyword\">import</span> load_iris</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.model_selection <span class=\"keyword\">import</span> train_test_split</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.preprocessing <span class=\"keyword\">import</span> StandardScaler</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.neighbors <span class=\"keyword\">import</span> KNeighborsClassifier</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">iris_demo</span>():</span></span><br><span class=\"line\">    <span class=\"comment\"># 1.准备数据</span></span><br><span class=\"line\">    iris = load_iris()</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 2.数据基本处理</span></span><br><span class=\"line\">    x_train, x_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=<span class=\"number\">0.2</span>, random_state=<span class=\"number\">22</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 3.特征工程</span></span><br><span class=\"line\">    <span class=\"comment\"># 3.1 标准化</span></span><br><span class=\"line\">    transfer = StandardScaler()</span><br><span class=\"line\">    x_train = transfer.fit_transform(x_train)</span><br><span class=\"line\">    x_test = transfer.transform(x_test)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 4.机器训练(模型训练)</span></span><br><span class=\"line\">    estimator = KNeighborsClassifier(n_neighbors=<span class=\"number\">3</span>)</span><br><span class=\"line\">    estimator.fit(x_train, y_train)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 5.模型评估</span></span><br><span class=\"line\">    <span class=\"comment\"># 5.1  方法1：比对真实值和预测值</span></span><br><span class=\"line\">    predict_data = estimator.predict(x_test)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&quot;预测值为: \\n&quot;</span>, predict_data)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&quot;比对真实值和预测值;\\n&quot;</span>, predict_data == y_test)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 5.2  方法2: 直接计算正确率</span></span><br><span class=\"line\">    score = estimator.score(x_test, y_test)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&quot;正确率:&quot;</span>, score)</span><br></pre></td></tr></table></figure>\n<h4 id=\"输出结果\"><a class=\"markdownIt-Anchor\" href=\"#输出结果\">#</a> 输出结果</h4>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">预测值为: </span><br><span class=\"line\"> [0 2 1 2 1 1 1 2 1 0 2 1 2 2 0 2 1 1 1 1 0 2 0 1 2 0 2 2 2 2]</span><br><span class=\"line\">比对真实值和预测值;</span><br><span class=\"line\"> [ True  True  True  True  True  True  True  True  True  True  True  True</span><br><span class=\"line\">  True  True  True  True  True  True False  True  True  True  True  True</span><br><span class=\"line\">  True  True  True  True  True  True]</span><br><span class=\"line\">正确率: 0.9666666666666667</span><br></pre></td></tr></table></figure>\n<h4 id=\"使用-gscv-优化\"><a class=\"markdownIt-Anchor\" href=\"#使用-gscv-优化\">#</a> 使用 GSCV 优化</h4>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> sklearn.datasets <span class=\"keyword\">import</span> load_iris</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.model_selection <span class=\"keyword\">import</span> train_test_split, GridSearchCV</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.preprocessing <span class=\"keyword\">import</span> StandardScaler</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.neighbors <span class=\"keyword\">import</span> KNeighborsClassifier</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">iris_demo</span>():</span></span><br><span class=\"line\">    <span class=\"comment\"># 1.准备数据</span></span><br><span class=\"line\">    iris = load_iris()</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 2.数据基本处理</span></span><br><span class=\"line\">    x_train, x_test, y_train, y_test = train_test_split(iris.data, iris.target, random_state=<span class=\"number\">22</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 3.特征工程</span></span><br><span class=\"line\">    <span class=\"comment\"># 3.1 标准化</span></span><br><span class=\"line\">    transfer = StandardScaler()</span><br><span class=\"line\">    x_train = transfer.fit_transform(x_train)</span><br><span class=\"line\">    x_test = transfer.transform(x_test)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 4.机器训练(模型训练)</span></span><br><span class=\"line\">    estimator = KNeighborsClassifier()</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 4.1 准备要调的超参数</span></span><br><span class=\"line\">    param_dict = &#123;<span class=\"string\">&quot;n_neighbors&quot;</span>: [<span class=\"number\">1</span>, <span class=\"number\">3</span>, <span class=\"number\">5</span>]&#125;</span><br><span class=\"line\">    <span class=\"comment\"># 4.2 创建 GridSearchCV,使用网格搜索和交叉验证</span></span><br><span class=\"line\">    estimator = GridSearchCV(estimator, param_grid=param_dict, cv=<span class=\"number\">3</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    estimator.fit(x_train, y_train)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 5.模型评估</span></span><br><span class=\"line\">    <span class=\"comment\"># 5.1  方法1：比对真实值和预测值</span></span><br><span class=\"line\">    predict_data = estimator.predict(x_test)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&quot;预测值为: \\n&quot;</span>, predict_data)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&quot;比对真实值和预测值;\\n&quot;</span>, predict_data == y_test)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 5.2  方法2: 直接计算正确率</span></span><br><span class=\"line\">    score = estimator.score(x_test, y_test)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&quot;正确率:&quot;</span>, score)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 6. 直接查看评估结果哦</span></span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&quot;在交叉验证中验证的最好结果：&quot;</span>, estimator.best_score_)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&quot;最好的参数模型：&quot;</span>, estimator.best_estimator_)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&quot;每次交叉验证后的准确率结果：\\n&quot;</span>, estimator.cv_results_)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">&#x27;__main__&#x27;</span>:</span><br><span class=\"line\">    iris_demo()</span><br></pre></td></tr></table></figure>\n<h4 id=\"输出结果-2\"><a class=\"markdownIt-Anchor\" href=\"#输出结果-2\">#</a> 输出结果</h4>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">预测值为: </span><br><span class=\"line\"> [0 2 1 2 1 1 1 1 1 0 2 1 2 2 0 2 1 1 1 1 0 2 0 1 2 0 2 2 2 2 0 0 1 1 1 0 0</span><br><span class=\"line\"> 0]</span><br><span class=\"line\">比对真实值和预测值;</span><br><span class=\"line\"> [ True  True  True  True  True  True  True False  True  True  True  True</span><br><span class=\"line\">  True  True  True  True  True  True False  True  True  True  True  True</span><br><span class=\"line\">  True  True  True  True  True  True  True  True  True  True  True  True</span><br><span class=\"line\">  True  True]</span><br><span class=\"line\">正确率: 0.9473684210526315</span><br><span class=\"line\">在交叉验证中验证的最好结果： 0.9732100521574205</span><br><span class=\"line\">最好的参数模型： KNeighborsClassifier()</span><br><span class=\"line\">每次交叉验证后的准确率结果：</span><br><span class=\"line\"> &#123;&#x27;mean_fit_time&#x27;: array([0.0008928 , 0.00045244, 0.00044529]), &#x27;std_fit_time&#x27;: array([5.74547103e-04, 5.05512361e-06, 2.92218150e-06]), &#x27;mean_score_time&#x27;: array([0.00226967, 0.00184425, 0.00182239]), &#x27;std_score_time&#x27;: array([6.28895378e-04, 2.09757168e-05, 1.41269575e-05]), &#x27;param_n_neighbors&#x27;: masked_array(data=[1, 3, 5],</span><br><span class=\"line\">             mask=[False, False, False],</span><br><span class=\"line\">       fill_value=&#x27;?&#x27;,</span><br><span class=\"line\">            dtype=object), &#x27;params&#x27;: [&#123;&#x27;n_neighbors&#x27;: 1&#125;, &#123;&#x27;n_neighbors&#x27;: 3&#125;, &#123;&#x27;n_neighbors&#x27;: 5&#125;], &#x27;split0_test_score&#x27;: array([0.97368421, 0.97368421, 0.97368421]), &#x27;split1_test_score&#x27;: array([0.97297297, 0.97297297, 0.97297297]), &#x27;split2_test_score&#x27;: array([0.94594595, 0.89189189, 0.97297297]), &#x27;mean_test_score&#x27;: array([0.96420104, 0.94618303, 0.97321005]), &#x27;std_test_score&#x27;: array([0.01291157, 0.03839073, 0.00033528]), &#x27;rank_test_score&#x27;: array([2, 3, 1], dtype=int32)&#125;</span><br></pre></td></tr></table></figure>\n<h3 id=\"预测facebook签到位置\"><a class=\"markdownIt-Anchor\" href=\"#预测facebook签到位置\">#</a> 预测 facebook 签到位置</h3>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> pandas <span class=\"keyword\">as</span> pd</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.model_selection <span class=\"keyword\">import</span> train_test_split</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.preprocessing <span class=\"keyword\">import</span> StandardScaler</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.neighbors <span class=\"keyword\">import</span> KNeighborsClassifier</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.model_selection <span class=\"keyword\">import</span> GridSearchCV</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">facebook_demo</span>():</span></span><br><span class=\"line\">    <span class=\"comment\"># 准备数据</span></span><br><span class=\"line\">    data = pd.read_csv(<span class=\"string\">&#x27;./train.csv&#x27;</span>)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(data.head())</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 2.数据基本处理</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">## 2.1 处理时间特征</span></span><br><span class=\"line\">    time = pd.to_datetime(data[<span class=\"string\">&#x27;time&#x27;</span>], unit=<span class=\"string\">&#x27;s&#x27;</span>)</span><br><span class=\"line\">    time = pd.DatetimeIndex(time)</span><br><span class=\"line\"></span><br><span class=\"line\">    data[<span class=\"string\">&#x27;hour&#x27;</span>] = time.hour</span><br><span class=\"line\">    data[<span class=\"string\">&#x27;day&#x27;</span>] = time.day</span><br><span class=\"line\">    data[<span class=\"string\">&#x27;weekday&#x27;</span>] = time.weekday</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"built_in\">print</span>(data.head(<span class=\"number\">10</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 2.2.去掉签到少的地方</span></span><br><span class=\"line\">    place_count = data.groupby(<span class=\"string\">&quot;place_id&quot;</span>).count()</span><br><span class=\"line\">    place_count = place_count[place_count[<span class=\"string\">&quot;row_id&quot;</span>] &gt; <span class=\"number\">3</span>]</span><br><span class=\"line\">    data = data[data[<span class=\"string\">&quot;place_id&quot;</span>].isin(place_count.index)]</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 2.3 确定特征和目标值</span></span><br><span class=\"line\">    x = data[[<span class=\"string\">&#x27;x&#x27;</span>, <span class=\"string\">&#x27;y&#x27;</span>, <span class=\"string\">&quot;accuracy&quot;</span>, <span class=\"string\">&quot;day&quot;</span>, <span class=\"string\">&quot;hour&quot;</span>, <span class=\"string\">&quot;weekday&quot;</span>]]</span><br><span class=\"line\">    y = data[[<span class=\"string\">&#x27;place_id&#x27;</span>]]</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 2.4 拆分数据集</span></span><br><span class=\"line\">    x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=<span class=\"number\">22</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 3. 特征处理</span></span><br><span class=\"line\">    <span class=\"comment\"># 3.1 标准化处理</span></span><br><span class=\"line\">    transfer = StandardScaler()</span><br><span class=\"line\">    x_train = transfer.fit_transform(x_train)</span><br><span class=\"line\">    x_test = transfer.transform(x_test)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 4.机器学习</span></span><br><span class=\"line\">    <span class=\"comment\"># 4.1 实例化估计器</span></span><br><span class=\"line\">    estimator = KNeighborsClassifier()</span><br><span class=\"line\">    param_dict = &#123;<span class=\"string\">&#x27;neighbors&#x27;</span>: [<span class=\"number\">1</span>, <span class=\"number\">3</span>, <span class=\"number\">5</span>]&#125;</span><br><span class=\"line\">    estimator = GridSearchCV(estimator=estimator, param_grid=param_dict)</span><br><span class=\"line\">    <span class=\"comment\"># 4.2 模型训练</span></span><br><span class=\"line\">    estimator.fit(x_train, y_train)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 模型评估</span></span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&quot;\\n最后预测的准确率为: &quot;</span>, estimator.score(x_test, y_test))</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&quot;\\n在交叉验证中验证的最好结果:\\n&quot;</span>, estimator.best_score_)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&quot;\\n最好的参数模型:\\n&quot;</span>, estimator.best_estimator_)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&quot;\\n每次交叉验证后的验证集准确率结果和训练集准确率结果:\\n&quot;</span>, estimator.cv_results_)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">&#x27;__main__&#x27;</span>:</span><br><span class=\"line\">    facebook_demo()</span><br></pre></td></tr></table></figure>\n<p>本案例来自  <code>Kaggle</code>  的题目，感兴趣的朋友可以登录:<span class=\"exturl\" data-url=\"aHR0cHM6Ly93d3cua2FnZ2xlLmNvbS9uYXZvc2h0YS9ncmlkLWtubi9zY3JpcHQ=\">https://www.kaggle.com/navoshta/grid-knn/script</span>  查看</p>\n<h2 id=\"最后\"><a class=\"markdownIt-Anchor\" href=\"#最后\">#</a> 最后</h2>\n<p>希望和你一起遇见更好的自己</p>\n<p><img data-src=\"/images/ml/qrcode.jpg\" alt=\"qrcode\"></p>\n",
            "tags": [
                "MachineLearn",
                "KNN"
            ]
        }
    ]
}